---
layout: post
title: "读薄《Professional CUDA C Programming》——CUDA编程模型"
author: dazuo
date: 2020-07-01 20:19:00 +0800
categories: [GPU]
tags: [GPU]
math: true
mermaid: true
---

# 二、CUDA编程模型

## 概述

### CUDA编程结构

站在程序员的角度，可以从以下几个不同层面来看待并行计算：

- 领域层(Domain level)
- 逻辑层(Logic level)
- 硬件层(Hardware level)

这三个层面对应了并行计算编程的不同阶段：

- 算法设计阶段， 最关心的应是在**领域层**如何解析数据和函数， 以便在并行环境中能正确、 高效地解决问题。 
- 编码阶段， 关注点应转向如何组织并发线程。 在这个阶段， 需要从**逻辑层面**来思考， 以确保线程和计算能正确地解决问题。 在C语言并行编程中， 需要使用`pthreads`或`OpenMP`技术来显式地管理线程。 CUDA提出了一个线程层次结构抽象的概念， 以允许控制线程行为。 
- 在**硬件层**， 通过理解线程是如何映射到核心可以帮助提高其性能。



CUDA编程模型主要是异步的， 因此在GPU上进行的运算可以与主机-设备通信重叠。 内核一旦被启动， 管理权立刻返回给主机， 释放CPU来执行由设备上运行的并行代码实现的额外的任务。 


### 内存管理

**CUDA运行时**负责分配与释放设备内存， 并且在主机内存和设备内存之间传输数据。

| 标准C函数 | CUDA C函数 |
| :------- | :--------- |
|  malloc   | cudaMalloc |
|   free    |   cudaFree |
|  memset   | cudaMemset |
|  memcpy   | cudaMemcpy |

cudaMemcpy的调用会导致主机运行阻塞。 


上图是一个简化的GPU内存结构， 它主要包含两部分： 全局内存和共享内存。全局内存类似于CPU的系统内存， 共享内存类似于CPU的缓存。 不过GPU的共享内存可以由CUDA C的kernel直接控制。



### 线程管理

当kernel函数在host侧启动时， 它的执行会移动到device侧， 此时设备中会产生大量的线程并且每个线程都执行由kernel函数指定的语句。


一个kernel函数启动后产生的所有线程统称为一个Grid。 同一Grid的所有线程共享全局内存空间。 一个Grid由多个thread blocks构成， 一个thread block包含一组线程，同一线程块内的线程协作可以通过2种方式来实现：Block-local synchronization和Block-local shared memory。（不同block内的线程不能协作）



#### 内置变量

- gridDim, grid dimension, measured in blocks
- blockDim, block dimension, measured in threads
- blockIdx, block index within a grid
- threadIdx, thread index within a block



### kernel函数

```cpp
void kernel_name <<<grid, block>>>(argument_list);
```

执行配置的第一个值是网格维度， 也就是启动块的数目。 第二个值是块维度， 也就是每个块中线程的数目。

下图所示就是`void kernel_name <<<4, 8>>>(argument_list);`配置下的线程布局。


#### CUDA核函数的限制

- 只能访问设备内存
- 必须具有void返回类型
- 不支持可变数量的参数
- 不支持静态变量
- 显式异步行为



#### 验证kernel函数

除了使用调试工具外， 还有两个非常简单实用的方法可以验证核函数。

- 在`Fermi`及更高版本的设备端的核函数中使用`printf`函数。
- 可以将执行参数设置为`<<<1, 1>>>`， 因此强制用`1`个块和`1`个线程执行核函数， 这模拟了串行执行。

