---
layout: post
title: "SIMD"
author: dazuo
date: 2022-07-03 20:19:00 +0800
categories: [SIMD]
tags: [SIMD]
math: true
mermaid: true
---


可以并行化执行是因为CPU在设计时，增加了一些专用的向量寄存器，这些寄存器的长度往往大于通用寄存器，比如`SEE`的`XMM`寄存器，位宽为`128`位，`AVX`和`AVX2`的`YMM`寄存器，位宽为`256`位。这些专用的向量寄存器可以同时放入多个数据。



# 变量定义

第一部分，统一为`__m`；

第二部分为位数如`64`、`128`、`256`等；

第三部位为变量类型，`i`表示`int`型，`d`表示`double`型，`float`型什么也不加。

例如`__m128i` 表示定义128位的`int`型数据。`__m256` 表示定义256位的`float`型数据。


$$
\underbrace{\_\_m}_{\text{前缀}}\underbrace{128}_{\text{位数}}\underbrace{\text{i}}_{\text{变量类型}}
$$


# 函数定义

第一部分：输出的数据类型的位数：`256`位`_mm256`，`512`位`_mm512`，`128`位不需要带数字：`_mm`；

第二部分：功能的名称例如，载入数据`load`，加法`add`，存储`store`；

第三部分：该功能的数据类型，如`8`位整数`epi8`、无符号`8`位整数`epu8`、`16`位整数`epi16`，单精度浮点数`_ps`，双精度浮点数`_pd`；

其中 p = packed，s = 单精度浮点数，d = 双精度浮点数，

- `ps`: 由float类型数据组成的向量
- `pd`:由double类型数据组成的向量
- `epi8`/`epi16`/`epi32`/`epi64`: 由8位/16位/32位/64位的有符号整数组成的向量
- `epu8`/`epu16`/`epu32`/`epu64`: 包含8位/16位/32位/64位的无符号整数组成的向量
- `si128`/`si256`: 未指定的128位或者256位向量



例如`_mm256_add_epi32(a, b)`,的意思是数据总位数为`256`，将`a`和`b`其中每`32`位为一个数字进行对应相加。也就是说`a`可以看作`a[0]`、`a[1]`、`a[2]`...`a[7]`。`b`看作`b[0]`、`b[1]`、`b[2]`...`b[7]`。然后`a[0]+b[0]`、`a[1]+b[1]`...`a[7]+b[7]`得到了新的结果。


$$
\underbrace{\_mm}_{\text{前缀}}\underbrace{256}_{\text{位数}}\underbrace{\text{\_add}}_{\text{功能}}\underbrace{\text{\_epi16}}_{\text{功能}}
$$



# 应用

MindSpore中为了方便各种位宽指令的统一编写，通过宏封装了intrinsic指令，如果需要看真正的指令，可以通过下面的命令

```shell
gcc -E -C ./build/mindspore/src/nnacl/avx512/layer_norm_fp32_avx512.h -I ./mindspore/ccsrc/plugin/device/cpu/kernel/ > intrinsic.h
```

比如，下面是部分宏与intrinsic指令的对应关系（avx512上）：

```c++
SIMD_F32 => __m512
SIMD_MOV_F32 => #define MS_MOV512_F32 _mm512_set1_ps
SIMD_LD_F32  => #define MS_LD512_F32  _mm512_loadu_ps
SIMD_FMADD_F32   => #define MS_FMADD512_F32(src1, src2, src3) _mm512_fmadd_ps(src1, src2, src3)
SIMD_GET_SUM_F32 => #define MS_GET_SUM512_F32(src) 		      _mm512_reduce_add_ps(src)

SIMD_SUB_F32 => #define MS_SUB512_F32 _mm512_sub_ps
SIMD_MUL_F32 => #define MS_MUL512_F32(src1, src2) _mm512_mul_ps(src1, src2)
SIMD_ST_F32  => #define MS_ST512_F32 _mm512_storeu_ps
```



[intel intrinsics-guide](https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html)

```c++
# broadcast singe-prcison (32-bit) floating-point value a to all elements of dst
__m512 _mm512_set1_ps(float a);

# set singe-prcison (32-bit) floating-point elements in dst with the supplied values.
__m512 _mm512_set_ps(float e15, float e14, ..., float e1, float e0);

将512位(由16个单精度(32-bit)打包的浮点数组成)从内存加载到dst中，mem_addr不需要对齐。
__m512 _mm512_loadu_ps(void const* mem_addr)

将512位(由16个单精度(32-bit)打包的浮点数组成)从内存加载到dst中，mem_addr必须64字节对齐，否则可能会产生通用保护异常。
__m512 _mm512_load_ps(void const* mem_addr)
```



同样，arm neon的也可以用类似处理。

```cpp
SIMD_F32 => float32x4_t
SIMD_MOV_F32 => #define MS_MOVQ_F32 vmovq_n_f32
SIMD_LD_F32  => #define MS_LDQ_F32  vld1q_f32
SIMD_FMADD_F32   => #define MS_MLAQ_F32(src1, src2, src3) vmlaq_f32(src1, src2, src3)
                    #define MS_FMADD128_F32(src1, src2, src3) vmlaq_f32(src3, src1, src2)
SIMD_GET_SUM_F32 => #define MS_ADDVQ_F32(src) vaddvq_f32(src)

SIMD_SUB_F32 => #define MS_SUBQ_F32 vsubq_f32
SIMD_MUL_F32 => #define MS_MULQ_F32(src1, src2) vmulq_f32(src1, src2)
SIMD_ST_F32  => #define MS_STQ_F32 vst1q_f32
```



根据Arm C语言扩展，arm_neon.h中的函数原型遵循一种通用模式。在最一般的层面上是：

```c++
ret v[p][q][r]name[u][n][q][x][_high][_lane | laneq][_n][_result]_type(args)
```

- `ret`  返回值类型.
- `v`    `vector`的首字母，所有`intrinsics`都有
- `p`   表示是一个成对操作`pairwise operation`
- `q`   表示是一个饱和操作`saturating operation` (`AArch64`下`vqtb[l][x]` 是例外，`q` 表示128-bit index and result operands).
- `r`   表示是一个舍入操作。
- `name`  基本操作的描述性名称。这通常是一条高级`SIMD`指令，但不一定是。
- `u`  表示有符号到无符号`saturation`.
- `n`  表示是一个`narrowing`操作.
- `q`  作为操作的后缀表示对128位向量的操作。
- `x`  表示`AArch64`中高级`SIMD`标量操作。它可以是`b/h/s/d`之一（即`[8/16/32/64]`位）。
- `_high`   在`AArch64`中，用于涉及128位操作数的`widening`和`narrowing`操作。对于`widening` 128位操作数，`high`指源操作数的前64位。对于`narrowing`，它指的是目标操作数的前64位。
- `_n`   指示作为参数提供的标量操作数。
- `_lane`  表示从向量的通道获取的标量操作数。`_laneq`表示从128-bit输入向量的通道中获取的标量操作数。
- `type`   缩写形式的主操作数类型。
- `args`   函数参数
