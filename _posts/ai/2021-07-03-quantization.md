---
layout: post
title: "量化"
author: dazuo
date: 2020-07-02 20:19:00 +0800
categories: [AI]
tags: [量化]
math: true
mermaid: true
---

业界量化方案：

- **感知量化训练**(Quantization Aware Training, **QAT**)，或者**在线量化**

  在模型中插入伪量化节点，其作用有二：

  - 找到输入、权重等待量化数据的分布，找到待量化数据的最大和最小值；
  - 模拟量化模型在量化到低比特时引入的精度损失(来自rounding和clamping操作)，将该损失作用到网络模型中，传递给损失函数，让优化器在训练过程中对该损失值进行优化，从而提高模型对量化效应的适应能力，获得更高的量化模型精度。

  优点：模型准确率更好，适用于对模型压缩率和准确率要求较高的场景。

- **训练后量化**(Post-training Quantization, **PAT**)，或者**离线量化**

  优点：简单易用，适用于追求高易用性和缺乏训练资源的场景。



量化算法

- 对称/非对称量化
- 逐层/逐通道量化



量化方案

- 4、7、8 bit量化

