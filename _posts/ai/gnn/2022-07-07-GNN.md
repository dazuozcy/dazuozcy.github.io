---
layout: post
title: "GNN"
author: dazuo
date: 2020-07-02 20:19:00 +0800
categories: [GNN]
tags: [GNN]
math: true
mermaid: true
---

- `CNN`系列： 做图像识别时，对象是图片，是一个二维的结构，于是人们发明了`CNN`这种神奇的模型来提取图片的特征。`CNN`的核心在于它的kernel，kernel是一个个小窗口，在图片上平移，通过卷积的方式来提取特征。这里的关键在于图片结构上的**平移不变性**： 一个小窗口无论移动到图片的哪一个位置，其内部的结构都是一模一样的，因此是`CNN`可以实现所在。

- `RNN`系列: 它的对象是自然语言这样的序列信息，是一个一维的结构，`RNN`就是专门针对这些序列的结构而设计的，通过各种"门"的操作，使得序列前后的信息互相影响，从而很好地捕捉序列的特征。

前面讲的图片或语言，都属于**欧式空间**的数据，有维度的概念，欧式空间数据的特点就是结构很规则。但是现实生活中，其实有很多不规则的数据结构，典型的就是图结构，或称**拓扑结构**，如社交网络、化学分子结构、知识图谱等等。
图的结构一般来说是十分不规则的，可以认为是**无限维**的一种数据，所以它**没有平移不变性**。每一个节点的周围结构可能都是独一无二的，这种结构的数据，就让传统的`CNN`、`RNN`瞬间失效。为了处理这类数据，涌现出了许多方法。



**欧几里得结构**: `CNN`处理的数据是矩阵形式，就是以像素点排列成的矩阵为基础。称为`Euclidean Structure`，欧几里得结构。

**拓扑结构**(图结构): `GCN`处理的数据是图结构，即`Non Euclidean Structure`非欧几里得结构，拓扑结构。如社交网络连接，信息网络等等。对于`Non euclidean structure`数据，卷积神经网络就没有用了。

`GNN`提供了一个通用且高效的框架来学习**图数据结构**。因此`GNN`很容易应用于数据可以表示为一组节点和预测取决于节点间关系（边）的领域。这样的领域包括分子学、社交网络、产品推荐等。图神经网络的两大主要功能：节点分类、图分类。

在`GNN`中，每个节点通过与其邻居交互来迭代更新其状态。`GNN`不同变体的主要区别在于每个节点如何聚合和组合其邻居和自己的表示。

对于卷积神经网络`CNN`，图片中提取特征，可采用卷积方式提取特征。但对于拓扑结构，只能用其他方法来提取特征。对图的特征提取分为`vertex domain`(`spatial domain`)空域和`spectral domain`频域。对于图结构的提取信息，也可用谱聚类的方法，这里暂不讨论。

- 空域(`vertex domain`)，典型模型`GAT`. 

  从空间上考虑图结构，即考虑目标节点和其他节点的几何关系，直接用相应顶点连接的neighbors来提取特征。

- 频域(`spectal domain`)，典型模型`GCN`. 

  对邻接矩阵做处理，进行特征分解得到特征值，卷积核作用在特征值上。特征向量被看做常量。



### **CNN和GNN的区别**

两者的卷积目的都是一样的，即提取特征。CNN一般用于处理欧式空间中的规则数据，比如图像或视频，每个元素的邻居个数是固定的，所以可以使用同样尺寸的卷积核来进行卷积运算。

而图数据比如社交网络、蛋白质相互作用网络属于不规则的数据结构，不能在欧式空间中表示。图中每个节点的邻居个数是不固定的，所以无法使用同样尺寸的卷积核进行卷积计算。GNN一般使用基于频域和基于空域这两种卷积方式提取图的空间特征。
