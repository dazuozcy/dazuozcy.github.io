---
layout: post
title: "GCNConv-Semi-Supervised Classification with Graph Convolutional Networks"
author: dazuo
date: 2020-07-02 20:19:00 +0800
categories: [GNN]
tags: [GCNConv]
math: true
mermaid: true
---

> [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907)

# 摘要

我们提出了一种可扩展的图结构数据上半监督学习方法，该方法是直接操作图的卷积神经网络的高效变体。我们通过谱图卷积的局部一阶近似来给出我们选择卷积结构的原因。

我们的模型与图的边数呈线性关系，并可以学习带有图的局部结构和节点的特征信息的隐藏层表示。在引文网络和知识图数据集上的大量实验中，我们证明了我们的方法比相关方法有显著的优势。



# 引言

我们考虑对图（如引用网络）中的节点（如文档）进行分类的问题，其中仅一小部分节点带有标签。该问题可以被定义为基于图的半监督学习，其中通过某种显式的基于图的正则化在图上平滑标签信息，例如，通过在损失函数中使用图拉普拉斯正则化项：




$$
\mathcal{L} = \mathcal{L}_{0} + \lambda \mathcal{L}_{\text{reg}} \ \text{, 其中} \ \mathcal{L}_{\text{reg}} = \sum_{i,j}A_{i,j} \Vert f(X_{i}) - f(X_{j}) \Vert^{2} = f(X)^{\top} \Delta f(X)
$$


这里，$\mathcal{L}_{0}$ 表示图的带标记部分的监督损失。$f(\cdot)$ 可以是类似神经网络的可微函数，$\lambda$ 是权重因子，$X$ 是节点特征向量 $X_{i}$ 的矩阵。$\Delta=D-A$ 表示无向图 $\mathcal{G} = (\mathcal{V}, \mathcal{E})$ 的非正规图拉普拉斯，该图具有 $N$ 个节点 $v_{i} \in \mathcal{V}$、边 $(v_{i},v_{j}) \in \mathcal{E}$、邻接矩阵 $A \in \mathcal{R}^{N \times N}$（二进制或加权）和度矩阵 $D_{ii} = \sum_{j} A_{ij}$。等式1的公式依赖于图中的连接节点可能共享相同标签的假设。然而，这种假设可能会限制建模能力，因为图边不一定必须带有节点相似性，但可能包含其他信息。

本工作中，我们直接使用神经网络模型 $f(X,A)$ 对图的结构进行编码，并针对带标签的所有节点在监督目标 $\mathcal{L}_{0}$ 上进行训练，从而避免了损失函数中基于图的显式正则化。在图的邻接矩阵上调节 $f(\cdot)$ 将允许模型从监督损失 $$\mathcal{L}_{0}$$ 中分布梯度信息，并将使其能够学习带标签和不带标签的节点表示。

我们的贡献是双重的：

- 我们为直接作用于图的神经网络模型引入了一种简单且性能良好的分层传播规则，并展示了如何从谱卷积的一阶近似中解释该规则。
- 我们演示了这种基于图的神经网络模型如何用于图中节点的快速和可扩展半监督分类。

在大量数据集上的实验表明，我们的模型在分类精度和效率（以挂钟时间衡量）方面均优于半监督学习的最新方法。



# 图的快速近似卷积

