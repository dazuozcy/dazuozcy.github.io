---
layout: post
title: "Tiling"
author: dazuo
date: 2020-07-02 20:19:00 +0800
categories: [AI]
tags: [Tiling]
math: true
mermaid: true
---

在深度学习网络中，`Conv`, `MatMul`等操作都会降维为矩阵乘`(GEMM)`进行计算，业界的深度学习计算库如`oneDNN`、`cuDNN`等都对`GEMM`计算做了很多优化，其中最常见且通用的手段就是对于内存层级的`tiling`。`Tiling`的目的主要是为了满足芯片**片上存储**及**计算流水线**的需求，以最大化**计算并行性**和**数据局部性**，从而发挥硬件的**极致性能**。



AI芯片内buffer size有限，参与一次AI CORE运算的输入输出数据量均是受限的，因此要做`tiling`，对大矩阵进行拆分，分块进行运算。

举例：

- 矩阵A大小：M=256, K=192
- 矩阵B大小：K=192, N=192
- Tiling方法：m=64, k=64, n=64。在M方向循环4次，K方向循环3次，N方向循环3次。每次计算结果(64*64)存在buffer中。

