[ { "title": "SIMD", "url": "/posts/simd/", "categories": "SIMD", "tags": "SIMD", "date": "2022-07-03 20:19:00 +0800", "snippet": "可以并行化执行是因为CPU在设计时，增加了一些专用的向量寄存器，这些寄存器的长度往往大于通用寄存器，比如SEE的XMM寄存器，位宽为128位；AVX和AVX2的YMM寄存器，位宽为256位；AVX512的ZMM寄存器，位宽为512位。这些专用的向量寄存器可以同时放入多个数据。变量定义第一部分，统一为__m；第二部分为位数如64、128、256等；第三部位为变量类型，i表示int型，d表示double型，float型什么也不加。例如__m128i 表示定义128位的int型数据。__m256 表示定义256位的float型数据。\\[\\underbrace{\\_\\_m}_{\\text{前缀}..." }, { "title": "AES-GCM加解密", "url": "/posts/aes-gcm/", "categories": "openssl", "tags": "AES-GCM", "date": "2022-05-25 20:19:00 +0800", "snippet": "什么是AES加密常见加密分为两类： 对称加密 AES(Advanced Encrtption Standard)是对称加密的一种，即加密和解密使用相同的密钥。 非对称加密 加密和解密使用不同的密钥，非对程算法比对称算法更复杂，运算速度更慢。 AES加密流程关键概念分组密码体制分组密码体制是指将明文分成一段一段的来加密，然后再把一段段密文拼起来成为最终的密文。AES加密会首先把明文分成若干段，每段数据长度必须是16字节，如果最后一段不够16字节，则padding成16字节。PaddingPadding就是把不满16字节的分组数据填满16个字节，有三种模..." }, { "title": "oneDNN", "url": "/posts/onednn/", "categories": "oneDNN", "tags": "oneDNN", "date": "2022-05-25 20:19:00 +0800", "snippet": "介绍oneDNN(前身为mkl-dnn和dnnl)，是intel开发的开源深度学习加速计算库，实现了部分常用神经网络算子，它是oneAPI的一部分。开发oneDNN库的目的是为了提高intel处理器和显卡上开发深度学习应用的性能，因此该库主要针对intel的CPU和GPU进行优化，对AArch64和NVIDIA GPU实验性支持。目前使用了oneDNN的应用有TensorFlow、Pytorch、Matlab、Mindspore等。oneDNN核心模块： Primitives. 封装了算子执行时需要的所有信息。加上attributes，primitives可以表示更复杂的融合算子。 ..." }, { "title": "C++ vs C", "url": "/posts/diff-between-c-cpp/", "categories": "C++", "tags": "C++", "date": "2020-07-04 20:19:00 +0800", "snippet": "C++之父Bjarne Stroustrup设计C++是为了回答这样的问题：如何直接而高效地操作硬件（如内存管理，进程调度，设备驱动），同时又支持高效的高层次抽象（抽象在代码中体现为函数、类、模板、概念和别名）？C++在1980年代仅仅是一个基于C和Simula语言功能的组合，在当时的计算机上作为系统编程的相对简单的解决方案，经过多年的发展，已经成长为一个远比当年更复杂和有效的工具，应用极其广泛。C++一直关注的两个问题 语言结构到硬件设备的直接映射 零开销抽象 What you don’t use, you don’t pay for .（你不用的东西，你就不需要..." }, { "title": "Profiling", "url": "/posts/gperf/", "categories": "profiling", "tags": "gperf, py-spy", "date": "2020-07-03 20:19:00 +0800", "snippet": "Intel自顶向下的微架构分析方法Python 和 C/C++ 拓展程序如何性能优化？看这一篇文就够LD_PRELOAD=/path/to/libprofiler.so.0 CPUPROFILE=output.prof ./program (args)pprof --pdf output.prof &amp;gt; output.pdfpy-spy record -o output_debug.svg --native -- python test.pypy-spy record --format speedscore -o output_debug.json --native -- p..." }, { "title": "git", "url": "/posts/git/", "categories": "git", "tags": "git", "date": "2020-07-03 20:19:00 +0800", "snippet": "覆盖本地文件# 同一个仓的远程分支覆盖本地分支git fetch --allgit reset --hard origin/master# 用remote仓的分支覆盖本地分支git fetch mindspore # mindspore是remote add的仓git reset --hard mindspore/master撤销addgit reset HEAD &amp;lt;file&amp;gt;patch命令git diff &amp;gt; patch // 本地变更，git diff的内容，生成patch文件git diff branchname --cached &..." }, { "title": "GDB", "url": "/posts/gdb/", "categories": "GDB", "tags": "GDB", "date": "2020-07-03 20:19:00 +0800", "snippet": "GDB基于ptrace系统调用实现ptrace提供了一种使父进程得以监视和控制其他进程的方式，它还能改变子进程中的寄存器和内核映像，因而可以实现断点调试和系统调用的跟踪。软断点(Software Breakpoint)：在断点位置插入特殊的指令(可以触发中断或者异常)。需要修改原始二进制文件。硬断点(Hardware Breakpoint)：依赖于硬件，需要配置寄存器。硬断点的数量通常是有限的。关于GDBgdb的启动 可执行文件，带参数 python调用.so core dump文件gdb调试堆栈添加，删除，启用，禁用断点（包括普通断点，条件断点，数据断点）查看当前断点下的调用堆栈..." }, { "title": "Fuzz", "url": "/posts/fuzz/", "categories": "Fuzz", "tags": "Fuzz", "date": "2020-07-03 20:19:00 +0800", "snippet": "Fuzz测试是一种自动化软件测试技术，为程序的输入构造随机数据，然后监视程序执行是否会出现异常，比如崩溃，断言失败，内存泄漏，条件竞争等。基本流程 确定测试目标 确定输入向量。例如文件数据、网络数据等 生成模糊测试数据 执行模糊测试 监视异常。监视目标程序是否产生异常，记录使程序产生异常的测试数据和异常的相关信息。 判断发现的漏洞是否可被利用。通过复现前面产生的异常，分析异常的原因，从而判断是否可利用。基本要求要实现高效的模糊测试，通常需要满足： 可重现性：测试者必须能够知道使程序产生异常的测试数据，根据该数据可以复现该异常。 可重用性：进行模块化开发，无需为一个新的目标..." }, { "title": "CMake", "url": "/posts/cmake/", "categories": "CMake", "tags": "CMake", "date": "2020-07-03 20:19:00 +0800", "snippet": "WhatCMake是一个开源、跨平台的工具，旨在构建、测试和打包软件。CMake通过简单的、独立于平台和编译器的配置文件来控制软件编译过程，并生成makefiles。CMake源文件以CMake编写的源文件以CMakeLists.txt命名或以.cmake为扩展名。可以使用include命令包含.cmake。与其他语言允许将源文件拆分为模块或头文件类似，.cmake里可以定义函数、宏等，然后在多个CMakeLists.txt中复用。CMakeLists.txt是CMake在构建项目时使用的主配置文件，当执行CMake时，它的第一件事就是查找此文件。CMake变量CMake中变量都是str..." }, { "title": "TensorFlow", "url": "/posts/tensorflow/", "categories": "TensorFlow", "tags": "TensorFlow", "date": "2020-07-03 20:19:00 +0800", "snippet": "TensorFlow v1下，训练一个TF模型有三个步骤： 定义输入和模型结构 创建tf.Session实例sess 执行sess.run()启动训练静态图静态图采用声明式编程范式（先编译后执行），根据前端语言（如python）描述的神经网络结构和参数信息构建固定的静成计算图，静态图在执行期间不依赖前端语言，而是由TF框架负责调度执行，因此非常适合做神经网络模型的部署。用户定义的静态图经序列化后用GraphDef表达，其包含的信息有：网络连接、参数设置、损失函数、优化器等。动态图动态图采用命令式编程范式，即编译与执行同时发生。动态图采用前端语言的解释器对用户代码进行解析，然后利用T..." }, { "title": "分布式框架Ray", "url": "/posts/ray/", "categories": "Ray", "tags": "Ray", "date": "2020-07-03 20:19:00 +0800", "snippet": "高性能分布式执行框架——Raypython分布式多进程框架 Ray" }, { "title": "pybind11", "url": "/posts/pybind/", "categories": "pybind11", "tags": "pybind11", "date": "2020-07-03 20:19:00 +0800", "snippet": "给 Python 算法插上性能的翅膀——pybind11 落地实践" }, { "title": "NUMA", "url": "/posts/numa/", "categories": "NUMA", "tags": "NUMA", "date": "2020-07-03 20:19:00 +0800", "snippet": "绑核通俗说就是把一个进程绑定到指定的cpu上，即指定进程只运行在指定cpu上。绑核的作用 可以控制进程运行耗时，比如大核主频高，绑定到大核上运行起来应该会比绑定到小核上运行耗时小。 可以优化缓存性能。如果进程没有绑定在一个cpu上，那么当该进程切换cpu时，新cpu的cache上没有该进程缓存的数据，就会导致cache miss，然后需要从内存加载数据，然后过一段时间切回去原来cpu之后，可能原来的cache里面的内容也失效了，又导致cache miss，那么这样来回切换就很影响性能。" }, { "title": "mmdetection", "url": "/posts/mmdetection/", "categories": "CV", "tags": "mmdetection", "date": "2020-07-03 20:19:00 +0800", "snippet": "官方文档# Trainpython tools/train.py configs/yolox/yolox_tiny_8x8_300e_coco.py# Testpython tools/test.py configs/yolox/yolox_tiny_8x8_300e_coco.py xxx.pth --eval mAPTrainTracebackFile &quot;./tools/train.py&quot;, line 189 in &amp;lt;module&amp;gt; main()File &quot;./tools/train.py&quot;, line 178 in..." }, { "title": "DGL", "url": "/posts/dgl/", "categories": "DGL", "tags": "DGL", "date": "2020-07-03 20:19:00 +0800", "snippet": "从源码安装git clone --recursive https://github.com/dmlc/dgl.gitcd buildmkdir build# CPU-only buildcmake ..# CUDA buildcmake -DUSE_CUDA=ON ..make -j32# install the python bindingcd ../pythonpython setup.py install" }, { "title": "Protocol Buffers", "url": "/posts/protobuf/", "categories": "Protocol Buffers", "tags": "Protocol Buffers", "date": "2020-07-03 20:19:00 +0800", "snippet": "介绍Protobuf(Google Protocol Buffer) 是一种用于对结构数据进行序列化的工具，从而实现数据存储和交换。 序列化： 将结构数据或者对象转换成能够用于存储和传输的格式。 反序列化： 在其他的计算环境中，将序列化后的数据还原为数据结构和对象。 Protobuf是类似于JSON、XML这样的数据交换格式。但是相比于JSON和XML，它更小，更快！优点： 性能高效：与XML相比，protobuf更小（3 ~ 10倍）、更快（20 ~ 100倍）、更为简单。 语言无关、平台无关：protobuf支持Java、C++、Python等多种语言，..." }, { "title": "Eigen", "url": "/posts/eigen/", "categories": "Eigen", "tags": "Eigen", "date": "2020-07-03 20:19:00 +0800", "snippet": "性能方面的措施 static allocation, temporary removal, unrolling, auto vectorization, cache-aware algorithms, multi-threading …" }, { "title": "一、Python对象初探", "url": "/posts/code_analysis_of_python/", "categories": "Python", "tags": "Python源码剖析", "date": "2020-07-03 20:19:00 +0800", "snippet": "在Python中，一个整数是一个对象，一个字符串是一个对象，整数类型、字符串类型也都是一个对象。一言以蔽之，“Python中一切皆对象”。" }, { "title": "Python", "url": "/posts/python/", "categories": "Python", "tags": "Python", "date": "2020-07-03 20:19:00 +0800", "snippet": "is和==区别Python中，万物皆对象。每个对象有3个属性： id：对象的地址，可通过内置函数id()查看对象引用的地址。 type：对象的类型，可通过内置函数type()查看对象的类型。 value：对象的值。a is b 实际上是比较id(a) == id(b)。a == b就是比较对象a的值和对象b的值是否相等。python的set()底层是什么数据结构hash表@property@property装饰器来创建只读属性，@property会将方法转换为相同名称的只读属性,可与所定义的属性配合使用，防止属性被修改。修饰方法，使方法可像属性一样访问class DataSet(o..." }, { "title": "理解__name__", "url": "/posts/name/", "categories": "Python", "tags": "Python", "date": "2020-07-03 20:19:00 +0800", "snippet": "if __name__ == &#39;main&#39;:的作用# test.pyprint (&#39;you are importing &#39;, __name__)if __name__ == &#39;main&#39;: print (&#39;you are executing &#39;, __name__)# hello.pyimport helloprint (&#39;you are executing hello.py &#39;, __name__)一个python文件有两种使用方式： 直接作为脚本执行，比如：python test.py 被其他p..." }, { "title": "list vs. tuple vs. set vs. dict", "url": "/posts/list_tuple_set_dict/", "categories": "Python", "tags": "Python", "date": "2020-07-03 20:19:00 +0800", "snippet": "list类似于C/C++中的动态数组，但是list里面的元素可以是不同类型有序，可重复，可修改，非同构创建list1 = [] # 创建空列表list2 = [1, &#39;hello&#39;, 3.14, &#39;world&#39;] # 创建非同构列表list3 = list((1, &#39;2&#39;, 3.14)) # tuple转list读/写list1 = [1, &#39;hello&#39;, 3.14, &#39;world&#39;]# 索引print (list1[1]) # 输出&#39;hello&#39;# 切片print (list1[1:3..." }, { "title": "Python性能分析工具cProfile", "url": "/posts/cProfile/", "categories": "Python", "tags": "cProfile", "date": "2020-07-03 20:19:00 +0800", "snippet": "Introduction to cProfilecProfile is a built-in python module that can perform profiling. It is the most commonly used profiler currently.But, why cProfile is preferred? It gives you the total run time taken by the entire code. It also shows the time taken by each individual step. This allows yo..." }, { "title": "openMP", "url": "/posts/openmp/", "categories": "openMP", "tags": "openMP", "date": "2020-07-03 20:19:00 +0800", "snippet": "IntroOpenMP是共享内存体系结构上的一个基于多线程的并行编程模型，适用于SMP共享内存多处理系统和多核处理器体系结构。支持C/C++/Fortran.OpenMP由三部分组成 编译器指令(compiler directives) 运行时库程序(runtime routines) 环境变量(environment variables)OpenMP’s machine modelOpenMP: Shared-Memory Parallel Programming ModelAll processors/cores access a shared main memory.Para..." }, { "title": "OpenMP库持续增加的内存占用", "url": "/posts/openmp-increasing-mem-use/", "categories": "openMP", "tags": "openMP, libgomp", "date": "2020-07-03 20:19:00 +0800", "snippet": "背景在长稳执行某网络时，出现了内存占用持续上升的问题。经过初步分析隔离，发现是某些算子引入的，因为把那几个算子打桩掉后，内存占用就稳定了。那几个算子有个共性，底层是调用的oneDNN库实现的。oneDNN库的算子有内存泄漏问题？目标分析oneDNN库的那几个算子为什么会内存泄漏。定位过程选择其中一个算子，梳理出调用流程，发现几处显式申请释放内存的操作，但都是严格匹配的，不会存在泄漏情况。隔离按照梳理出的流程逐步隔离，发现问题出在算子里实现并行化的地方。parallel(nthr_to_use, [&amp;amp;](int ithr, int nthr) { /* do some..." }, { "title": "OpenMP in oneDNN", "url": "/posts/openmp-in-onednn/", "categories": "openMP", "tags": "openMP, oneDNN", "date": "2020-07-03 20:19:00 +0800", "snippet": "本文介绍下OpenMP在oneDNN库中的使用。parallel()oneDNN中CPU上多线程并行的基础是parallel()函数，将与OpenMP无关的内容删除以后，精简如下所示：// src/common/dnnl_thread_parallel_nd.hppinline int adjust_num_threads(int nthr, size_t work_amount) { if (nthr == 0) nthr = dnnl_get_current_num_threads();#if DNNL_CPU_THREADING_RUNTIME == DNNL_RUNTIME..." }, { "title": "Introduction to openMP", "url": "/posts/introdution-to-openmp-intel/", "categories": "openMP", "tags": "openMP", "date": "2020-07-03 20:19:00 +0800", "snippet": "这是一门非常优秀的OpenMP入门教程，讲解人Tim Mattson也曾参与过OpenMP的开发。1. 概述课程是简洁的lectures + 简短的execises的方式，讲究边学边练边掌握。课程由五大模块组成，每个模块由一系列单元和讨论组成： Getting Started with OpenMP The Core Features of OpenMP Working with OpenMP Advanced OpenMP Topics Recapitulation总共27个lecture。2. 并行编程介绍-1摩尔定律说集成电路上可容纳的晶体管数量大约每18个月便会增加一倍..." }, { "title": "面向对象的特性", "url": "/posts/object-oriented-character/", "categories": "C++", "tags": "面向对象", "date": "2020-07-03 20:19:00 +0800", "snippet": " 如果一个程序员了解底层实现模型，他就能够写出效率较高的代码，自信心也比较高。 ​ ——《深度探索C++对象模型》封装，继承，多态封装ADT(Abstract Data Type, 抽象数据类型)。“一个ADT或class hierarchy的数据封装”比“在C程序中程序性地使用全局数据”好。C++在布局及存取时间上主要的额外负担是由virtual引起的，包括： virtual function机制。用以支持一个有效率的“运行期绑定”。 virtual base class。用以实现“多次出现在继承体系中的..." }, { "title": "C++11开始的新特性", "url": "/posts/new-from-cpp11/", "categories": "C++", "tags": "C++11", "date": "2020-07-03 20:19:00 +0800", "snippet": "C++11新特性语言 Initializer list variadic templates move auto range-based for loop lambda标准库 type traits unordered container forward list array tuple con-currency regexinitializer list(初始化列表， since c++11)统一的类成员初始化方法与std::initializer_list。在C++11中可以直接在变量名后面加上初始化列表来进行对象的初始化。例如：struct A..." }, { "title": "C++里好的编码技巧", "url": "/posts/good-practice-in-cpp/", "categories": "C++", "tags": "C++", "date": "2020-07-03 20:19:00 +0800", "snippet": "SFINAEhttps://modern-cpp.readthedocs.io/zh_CN/latest/sfinae.htmlstatic auto Anyone = [](auto&amp;amp;&amp;amp; k, auto&amp;amp;&amp;amp;... args) { return ((args == k) || ...); };string s=&quot;autumn&quot;;//等价于 if(s==&quot;spring&quot; || s== &quot;summer&quot; || s == &quot;autumn&quot; || s =..." }, { "title": "四种类型转换", "url": "/posts/four-kinds-of-cast/", "categories": "C++", "tags": "类型转换", "date": "2020-07-03 20:19:00 +0800", "snippet": "static_cast主要用于基本类型之间和具有继承关系的类型之间的转换。这种转换一般会更改变量的内部表示方式，因此，static_cast应用于指针类型转换没有太大意义.例： //基本类型转换 int i=0; double d = static_cast&amp;lt;double&amp;gt;(i); //相当于 double d = (double)i; //转换继承类的对象为基类对象 class Base{}; class Derived : public Base{}; Derived d; Base b = static_cast&amp;lt;Base&amp;gt;(..." }, { "title": "class的内存模型", "url": "/posts/empty-class/", "categories": "C++", "tags": "空类，深拷贝，浅拷贝", "date": "2020-07-03 20:19:00 +0800", "snippet": "关于默认构造函数 惟有当默认构造函数被需要(被调用)，它们才会被编译器创建出来。什么是默认构造函数默认构造函数是可以不用实参进行调用的构造函数，它包括了以下两种情况： 没有带明显形参的构造函数。 提供了默认实参的构造函数。类设计者可以自己写一个默认构造函数。编译器帮我们写的默认构造函数，称为“合成的默认构造函数”。强调“没有带明显形参”的原因是编译器总是会为构造函数形参表插入一个隐含的this指针，所以”本质上”是没有不带形参的构造函数的，只有不带明显形参的构造函数，它就是默认构造函数。默认构造函数什么时候被调用如果定义一个对象时没有提供初始化式，就使用默认构造函数。例如：clas..." }, { "title": "构造函数与析构函数", "url": "/posts/constructor-destructor/", "categories": "C++", "tags": "构造函数, 析构函数", "date": "2020-07-03 20:19:00 +0800", "snippet": "介绍需要一个机制来建立一个工作环境（构造函数）和一个逆操作来释放运行期获得的资源（析构函数）。以下摘自1979 年的实验记录本： “new 函数”为成员函数创建运行的环境 “delete 函数”则执行相反的操作 构造函数为什么需要构造函数在C里面，经常需要给变量赋初值，也就是变量的初始化。如果变量比较多，一般会有个init()函数将所有的变量都初始化一遍。在C++里，一个类对象也有或多或少的成员变量，它们也需要被初始化。但是如果使用像init()这样的函数对类对象提供初始化功能既不优雅也容易出错。这种方式没有规定一个对象必须进行初始化，程序员可能忘记初始化，或者初始化了..." }, { "title": "二进制优化", "url": "/posts/binary_opt/", "categories": "LLVM", "tags": "binary optimization", "date": "2020-07-03 20:19:00 +0800", "snippet": "二进制优化工具BOLT是Facebook开发的基于LLVM的工具，它利用反馈数据(perf采样或插桩)优化二进制布局以提高应用程序性能。BOLT对应用的优化作用主要来自与BB块重排、函数重排、冷热分区。BB块BB块(Basic Block)是编译器对代码进行编译分析的最小单元。编译器把程序拆分为许多BB块进行分析。BB块组成了一个程序控制流图的节点，具有一下特征： 只有一个入口，即程序中不会有任何其他地方能通过jump等跳转类指令进入到此BB块。 只有一个出口，即程序中只有最后一条指令能触发进入到其他BB块。所以，BB块是一个程序顺序执行时跳转的基本单元。function foo(i..." }, { "title": "LLVM", "url": "/posts/llvm/", "categories": "LLVM", "tags": "LLVM", "date": "2020-07-03 20:19:00 +0800", "snippet": "LLVM介绍https://aosabook.org/en/llvm.htmlLLVM一开始就被设计为一组具有良好定义接口的可重用库。不像GCC那样很难重用它的parser来进行静态分析或者重构。LLVM设计最重要的方面是LLVM中间表示(IR).写一个LLVM Pass# 生成.bc./bin/clang++ -emit-llvm -c hello.cpp -o hello.bc -isystem /usr/include/c++/4.8.5# 将pass应用于生成的.bc./bin/opt -enable-new-pm=0 -load ./lib/LLVMHello.so -hell..." }, { "title": "IPA", "url": "/posts/IPA/", "categories": "GCC", "tags": "IPA", "date": "2020-07-03 20:19:00 +0800", "snippet": "过程间分析(Inter-Procedural Analysis)是一个多步骤的过程，是LTO分析过程中的重要部分，也是一个跨模块的分析过程。过程间分析包含local分析和global分析。局部分析会为每一个过程和调用点生成Local Summary；全局分析时会根据具体要解决的数据流问题在Local Summary中去查找。IPA 选项-fipa-pure-const Discover which functions are pure or constant. Enabled by default at ‘-O1’ and higher.检测空函数或者常量函数。-fipa-cp Pe..." }, { "title": "Memory-Hierarchies-Matrix-Multiplication", "url": "/posts/Memory-Hierarchies-Matrix-Multiplication/", "categories": "Parallel Computing", "tags": "Parallel Computing", "date": "2020-07-03 20:19:00 +0800", "snippet": "Memory-Hierarchies-Matrix-Multiplication" }, { "title": "Introduction to Parallel Computing-From Algorithms to Programming on State-of-the-Art", "url": "/posts/Introduction-to-Parallel-Computing-From-Algorithms-to-Programming-on-State-of-the-Art/", "categories": "Parallel Computing", "tags": "Parallel Computing", "date": "2020-07-03 20:19:00 +0800", "snippet": "1. Why Do We Need Parallel Programming1.1 Why-Every Computer Is a Parallel ComputerNowadays, all computers are essentially parallel. The parallelism is found on all levels of a modern computer’s architecture: 处理器架构层级。 比如SIMD. 多核处理器层级。 many servers contain several multi-core processors. even c..." }, { "title": "Berkeley-CS267", "url": "/posts/Berkeley-CS267/", "categories": "Parallel Computing", "tags": "Parallel Computing", "date": "2020-07-03 20:19:00 +0800", "snippet": "A parallel computer is about how things are connected together the network that connects the parallel computers together and they can be connected in a number of different ways we’re going to take separate processrorsand connect them together to make a parallel computerIt’s all about the need for..." }, { "title": "variadic template", "url": "/posts/variadic-template/", "categories": "C++", "tags": "variadic-template", "date": "2020-07-03 10:19:00 +0800", "snippet": "variadic templates可变参数模板，是C++11新增的强大的特性之一，它对模板参数进行了高度泛化，能表示0到任意个数、任意类型的参数。 谈的是templates function template class template 变化的是template parameters 参数个数，利用参数个数逐一递减的特性，实现递归调用，基于function template 参数类型，利用参数个数逐一递减导致参数类型数量也逐一递减的特性实现递归继承或者递归复合，基于class template可以方便地完成递归函数调用。可以方便地完成递归类继承。可变模板参数函数templ..." }, { "title": "智能指针", "url": "/posts/smart-pointers/", "categories": "C++", "tags": "智能指针", "date": "2020-07-03 10:19:00 +0800", "snippet": "4种智能指针shared_ptr中循环引用怎么解决？shared_ptr使用了引用计数，每个shared_ptr的拷贝都指向相同的内存，每次拷贝都会触发引用计数+1，每次生命周期结束析构的时候引用计数-1，在最后一个shared_ptr析构时，内存才会释放。如下图左边代码存在shared_ptr循环引用问题，aptr和bptr的引用计数为2，离开作用域后aptr和bptr的引用计数减1，但不会为 0，导致指针永远不会析构， 产生了内存泄漏。可以通过weak_ptr来解决，如下图右边代码所示。weak_ptr用来监视shared_ptr的生命周期，它不管理shared_ptr内部的指针，它..." }, { "title": "Modern C++", "url": "/posts/modern_cpp/", "categories": "C++", "tags": "智能指针", "date": "2020-07-03 10:19:00 +0800", "snippet": "const——支持接口和符号常量的不变性。虚函数——提供运行期多态。引用——支持运算符重载和简化参数传递。运算符和函数重载——除了算法和逻辑运算符外，还包括：允许用户定义 =（赋值）、()（调用；支持函数对象（§4.3.1））、[]（下标访问）和 -&amp;gt;（智能指针）。类型安全链接——消除许多来自不同翻译单元中不一致声明的错误。抽象类——提供纯接口。模板——在经历了多年使用宏进行泛型编程的痛苦之后，更好地支持泛型编程。异常——试图给混乱的错误处理带来某种秩序；RAII（§2.2.2）便是为此目标而设计的。dynamic_cast 和 typeid——一种非常简单的运行期反射形式..." }, { "title": "关键字", "url": "/posts/keywords/", "categories": "C/C++", "tags": "关键字", "date": "2020-07-03 10:19:00 +0800", "snippet": "externextern是C/C++中表明函数或全局变量作用域(可见性)的关键字，该关键字告诉编译器其修饰的符号可在本模块或者其他模块中使用。与extern相对的是static关键字，被static修饰的符号只能在本模块使用。extern与static是对立的，不可能同时修饰同一符号。C++中被extern &quot;C&quot;修饰的变量或者函数是按照C的规则进行编译和链接的，方便在C/C++混合编程。C/C++混合编程中需要通过extern &quot;C&quot;来区分C符号的原因是：C++支持函数重载，C++编译出来的函数符号带有函数名和参数信息，而C编译出来的函数符号只有..." }, { "title": "一、计算机系统漫游", "url": "/posts/a-tour-of-computer-system/", "categories": "CSAPP", "tags": "编译", "date": "2020-07-02 20:19:00 +0800", "snippet": " Information Is Bits + Context.编译过程预处理预处理器根据以#开头的命令，修改原始的C程序。比如插入#include的头文件、进行宏(#define)的替换、删除注释等操作，生成的文件名后缀为.i。g++ -E main.cpp &amp;gt; main.i #-E让g++只进行预处理操作编译将预处理过后的文件翻译成汇编文件，文件名后缀.s。g++ -S main.i #-S让g++只进行编译操作编译过程包括词法分析，语法分析，语义分析，中间代码生成，优化等一系列中间操作。汇编将汇编文件翻译成机器指令，并且把这些指令按照固定的规则进行打包，成为可重定..." }, { "title": "二、信息的表示和处理", "url": "/posts/Representing-and-Manipulating-Information/", "categories": "CSAPP", "tags": "bits", "date": "2020-07-02 20:19:00 +0800", "snippet": "信息存储程序将内存视为一个非常大的字节数组，称为虚拟内存。内存的每一个字节都有一个唯一的数字来标识，称为地址。所有可能地址的集合就是虚拟地址空间。浮点运算是不可结合的。(3.14 + 1e20) - 1e20 =&amp;gt; 0.03.14 + (1e20 - 1e20) =&amp;gt; 3.14整数运算和浮点运算会有不同的数学属性是因为它们处理数字表示有限性的方式不同： 整数的表示只能编码一个相对较小的数值范围，但是这种表示是精确的。 浮点数可以编码一个较大的数值范围，但是这种表示是近似的。大量的计算机漏洞都是由于计算机算术运算的微妙细节引起的。移动k位，K超过机器的位宽w..." }, { "title": "三、程序的机器级表示", "url": "/posts/Machine-Level-Representation-of-Programs/", "categories": "CSAPP", "tags": "assemble", "date": "2020-07-02 20:19:00 +0800", "snippet": "机器级代码调用者保存 vs. 被调用者保存如下图所示，func_A中会调用func_B，调用者保存就是在func_A中调用func_B之前保存rbx寄存器值，调用funcB之后恢复rbx值；被调用者保存就是在被调用函数func_B中使用rbx寄存器之前保存rbx，在使用rbx之后恢复rbx。访问信息一个x86-64的CPU包含一组16个64-bit的通用目的寄存器，这些寄存器用来存储整数数据和指针。每个寄存器都有特殊的用途 被调用者保存寄存器：%rbx，%rbp，%r12，%r13，%r14，%r15 调用者保存寄存器：%r10，%r11，%rax，%rdi，%rsi，%rdx，%r..." }, { "title": "Forecasting at Scale总结", "url": "/posts/forecasting_at_scale_summary/", "categories": "时间序列预测", "tags": "Forecasting at Scale", "date": "2020-07-02 20:19:00 +0800", "snippet": "原文链接： Forecasting at scale引言时间序列预测的难点 通常的预测算法无法融入专家的经验和假设 算法调试难度大 时间序列预测领域的专业人才比较稀缺希望解决的问题 降低算法门槛 适用于各种不同类型的预测问题 全自动产生大量序列的预测结果 可以将专家经验结合到预估算法中商业时间序列的特点图2: Facebook上创建的事件数。每一天对应一个点，点按周的天数进行颜色编码，以显示周周期。该时间序列的特征代表了许多商业时间序列：多重强季节性、趋势变化、异常值和假日效应。四个组成分量 Trend 较长一段时间内呈现出来的持续向上或持续向下的变动。 ..." }, { "title": "Forecasting at Scale", "url": "/posts/forecasting_at_scale/", "categories": "时间序列预测", "tags": "Forecasting at Scale", "date": "2020-07-02 20:19:00 +0800", "snippet": "原文链接： Forecasting at scale摘要预测是一项常见的数据科学任务，可帮助组织进行容量规划、目标设定和异常检测。虽然预测很重要，但是在产生可靠和高质量的预测方面存在着严重的挑战，特别是面对各种时间序列，具有时间序列建模方面专业知识的分析师相对较少时。为了解决这些挑战，我们描述了一种实用的大规模预测方法，它将可配置模型与分析师分析相结合。我们提出了一个带可解释参数的模块化回归模型，分析师可以基于时间序列的领域知识直观地调整这些参数。我们描述了性能分析，以比较和评估预测过程，并自动标记预测，以供手动审查和调整。帮助分析师最有效地利用其专业知识的工具实现了可靠、实用的商用时间..." }, { "title": "时间序列预测", "url": "/posts/time_series_predict/", "categories": "时间序列预测", "tags": "时间序列", "date": "2020-07-02 20:19:00 +0800", "snippet": "时间序列时间序列是按时间顺序出现的有序数列。数列就是某一统计指标的数值，比如：工厂订单数量、股票价格、网页访问量等。时间序列预测时间序列的待预测变量称为观察值。时间序列预测是指：基于历史数据预测未来的观察值。预测分为2种： 点预测。预测某一时间点上的具体数值 区间预测。预测某一时间点上数值的区间。时间序列可预测的前提： 了解时间序列观测值的影响因素 有可利用的历史数据 预测不会影响试图预测的结果时间序列可定量预测的前提： 过去的一些模式会在未来延续下去。术语 观察值 时间序列需要预测的值。 外部变量 影响观察值的其他变量。 误..." }, { "title": "量化", "url": "/posts/google-2017/", "categories": "AI", "tags": "量化", "date": "2020-07-02 20:19:00 +0800", "snippet": " 《Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference》摘要提出了一种量化方案：允许使用整型进行推理，在常用的只支持整型计算单元的硬件上可以比浮点推理效率更高。还设计了一种训练方案，使得端到端模型精度和时延之间有更好的权衡。引言很广泛的研究：在精度损失较小的前提下，减小模型体积和推理时间。主要分为2类： 设计新网络架构，以高效利用计算/内存操作。 将32位浮点的权重或者激活量化到低比特的表示。" }, { "title": "量化", "url": "/posts/quantization/", "categories": "AI", "tags": "量化", "date": "2020-07-02 20:19:00 +0800", "snippet": "量化根据是否需要重训练，分为： 感知量化训练，优点：模型准确率更好，适用于对模型压缩率和准确率要求较高的场景。 训练后量化，优点：简单易用，适用于追求高易用性和缺乏训练资源的场景。 训练后量化Post-training Quantization, PAT，或者离线量化。在模型训练结束后进行的量化，对训练后模型中的权重由浮点数(如float32)量化到低比特整数(如int8/int4)，并通过少量校准数据基于推理过程对数据(activation)进行校准量化，从而加速模型推理速度。通常，训练后的模型权重已经确定，因此可根据权重的数值离线计算得到权重的量化参数。而通..." }, { "title": "probability_programming", "url": "/posts/probability_programming/", "categories": "probability_programming", "tags": "AI", "date": "2020-07-02 20:19:00 +0800", "snippet": "概率编程深度学习模型具有强大的拟合能力，但是可解释性较弱，而贝叶斯理论从概率分布的角度提供了较好的可解释能力。概率编程是在贝叶斯学派的概率推理和贝叶斯定理的基础上提出来的：从一个预定义数据开始，称之为“先验(prior)”，然后收集一些数据，基于该数据更新先验，得到的结果称为“后验(posterior)”。然后，用更多的数据来处理后验，并使之变为先验。这个过程不断重复，直到得到最终答案。概率推理的目标是找到与一个或多个观测值一致的概率分布。Edward2随机变量rv带有一个概率分布，它是一个TF分布实例，用于控制随机变量的方法，例如log_prob和sample.默认情况下，实例化一个随..." }, { "title": "内存同步模式", "url": "/posts/host2device_async/", "categories": "MindSpore", "tags": "内存同步", "date": "2020-07-02 20:19:00 +0800", "snippet": "原始：AscendSession::RunOpImplOrigin() ↓AscendSession::LoadInputData() // load input data to device ↓for (size_t i = 0; i &amp;lt; inputs.size(); ++i) { AscendDeviceAddress::SyncHostToDevice()} ↓ SyncStream() SyncMemory() ↓ rtMemcpy()修改后：AscendSession::RunOpImplOrigin() ↓AscendSessi..." }, { "title": "图缓存", "url": "/posts/graph_info_cache/", "categories": "MindSpore", "tags": "图缓存", "date": "2020-07-02 20:19:00 +0800", "snippet": "PyNative模式下，模型是一个算子一个算子下发执行。每个step里每个算子都要先编译再执行。非动态shape场景下(大部分情况)，某个算子在step之间除了输入数据不同，其他都一样。这种情况下，第二个step开始的算子编译就属于重复工作，没有必要了。通过缓存机制，就可以节省第二个step开始的算子编译时间。增加日志打印，如下所示。diff --git a/mindspore/ccsrc/runtime/pynative/op_compiler.cc b/mindspore/ccsrc/runtime/pynative/op_compiler.ccindex 9db48047fe..a..." }, { "title": "动静态图", "url": "/posts/dynamic_static/", "categories": "MindSpore", "tags": "动静态图", "date": "2020-07-02 20:19:00 +0800", "snippet": "目前主流的深度学习框架有静态图(Graph)和动态图(PyNative)两种执行模式。 静态图模式下，程序在编译执行时，首先生成神经网络的图结构，然后再执行图中涉及的计算操作。因此，在静态图模式下，编译器可以通过使用图优化等技术来获得更好的执行性能，有助于规模部署和跨平台运行。 动态图模式下，程序按照代码的编写顺序逐行执行，在执行正向过程中根据反向传播的原理，动态生成反向执行图。这种模式下，编译器将神经网络中的各个算子逐一下发到设备进行计算操作，方便用户编写和调试神经网络模型。 在MindSpore中，动态图模式又称为PyNative模式，静态图模式又被称为Gr..." }, { "title": "AdamWeightDecay fission", "url": "/posts/adam_weight_decay_fission/", "categories": "MindSpore", "tags": "AdamWeightDecay, fission", "date": "2020-07-02 20:19:00 +0800", "snippet": " Ascend上AdamWeightDecay优化器是通过小算子组成而成，代码见附录。 Pynative模式下正向过程完全是按照Python语法进行执行，对于某个小算子，就是从Python侧通过pybind11调用C++侧实现。所以多个小算子就会涉及到Python侧与C++侧的多次切换。基于上面2点，有一种Pynative模式下网络训练性能优化的思路：在Python侧把AdamWeightDecay做成一个大算子，然后通过后端Fission pass把大算子拆成对应小算子。这样大大减少Python侧与C++侧切换次数，提升了性能(Bert Base 单step提升500ms)。这里C..." }, { "title": "GCNConv-Semi-Supervised Classification with Graph Convolutional Networks", "url": "/posts/GCNConv/", "categories": "GNN", "tags": "GCNConv", "date": "2020-07-02 20:19:00 +0800", "snippet": " Semi-Supervised Classification with Graph Convolutional Networks摘要我们提出了一种可扩展的图结构数据上的半监督学习方法，该方法是直接操作图的卷积神经网络的高效变体。我们通过谱图卷积的局部一阶近似来给出我们选择卷积结构的原因。我们的模型与图的边数呈线性关系，并可以学习带有图的局部结构和节点的特征信息的隐藏层表示。在引文网络和知识图数据集上的大量实验中，我们证明了我们的方法比相关方法有显著的优势。引言我们考虑对图（如引用网络）中的节点（如文档）进行分类的问题，其中仅一小部分节点带有标签。该问题可以被定义为基于图的半监督学习，..." }, { "title": "GATConv-Graph Attention Networks", "url": "/posts/GATConv/", "categories": "GNN", "tags": "GATConv", "date": "2020-07-02 20:19:00 +0800", "snippet": " GRAPH ATTENTION NETWORKS摘要我们提出了图注意网络GATs，这是一种操作图结构数据的新型神经网络架构，利用masked self-attentional层来解决现有的基于图卷积或其近似的方法的缺点。通过堆叠里面的节点能影响其邻域特征的层，我们可以（隐式地）为邻域中的不同节点指定不同的权重，而不需要任何复杂的矩阵运算（如求逆），也不需要事先知道图结构。通过这种方式，我们同时解决了基于谱的图神经网络的几个关键挑战，并使我们的模型易用于归纳(inductive)和推导(transductive)问题。我们的GAT模型已经在四个推导和归纳图的基准上达到或匹配了最新结果：..." }, { "title": "EGConv-DO WE NEED ANISOTROPIC GRAPH NEURAL NETWORKS", "url": "/posts/EGConv/", "categories": "GNN", "tags": "EGConv", "date": "2020-07-02 20:19:00 +0800", "snippet": " The Efficient Graph Convolution from the “Adaptive Filters and Aggregator Fusion for Efficient Graph Convolutions” paper.摘要GNN社区的常识表明：各向异性模型(模型中节点间发送的消息是源节点和目标节点的函数)用来实现最先进的性能。目前的benchmarks表明，这类模型的性能优于类似的各向同性模型(模型中消息仅是源节点的函数)。在本文中，我们提供了挑战这一常识的实践证据：提出了一种各向同性GNN，高效图卷积( EGC)，它通过使用空间自适应滤波器 spatiall..." }, { "title": "ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting", "url": "/posts/ASTGCN/", "categories": "GNN", "tags": "ASTGCN", "date": "2020-07-02 20:19:00 +0800", "snippet": " Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting摘要交通流预测是交通领域研究者和实践者面临的一个关键问题。然而由于交通流的高度非线性和复杂的模式，交通流问题非常具有挑战性。现有的大多数交通流预测方法缺乏对交通数据的动态时空相关性的建模能力，因此无法产生令人满意的预测结果。本文提出了一种新的基于注意力机制的时空图卷积网络模型(ASTGCN)来解决交通流预测问题。ASTGCN主要由三个独立部分组成，分别模拟交通流的三个时间特性：最近、每日和每周的依赖。更具体..." }, { "title": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering", "url": "/posts/chebnet/", "categories": "GNN", "tags": "Chebnet", "date": "2020-07-02 20:19:00 +0800", "snippet": "Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering摘要本文主要研究将CNN从低维的规则化网格(如图像、视频或语音)推广到用图表示的高维不规则域(如社交网络、大脑连接体或单词嵌入)。我们在谱图论的背景下提出了一个CNN的公式，它为在图上设计快速局部化卷积滤波器提供了必要的数学背景和有效的数值方案。重要的是，该技术提供了与经典CNN相同的线性计算复杂度和常量学习复杂度，同时适用于任何图结构。在MNIST和20NEWS上的实验证明了这种新型深度学习系统学习图的局部、平稳和组合特征的能力。引..." }, { "title": "GNN", "url": "/posts/GNN/", "categories": "GNN", "tags": "GNN", "date": "2020-07-02 20:19:00 +0800", "snippet": " CNN系列： 做图像识别时，对象是图片，是一个二维的结构，于是人们发明了CNN这种神奇的模型来提取图片的特征。CNN的核心在于它的kernel，kernel是一个个小窗口，在图片上平移，通过卷积的方式来提取特征。这里的关键在于图片结构上的平移不变性： 一个小窗口无论移动到图片的哪一个位置，其内部的结构都是一模一样的，因此是CNN可以实现所在。 RNN系列: 它的对象是自然语言这样的序列信息，是一个一维的结构，RNN就是专门针对这些序列的结构而设计的，通过各种”门”的操作，使得序列前后的信息互相影响，从而很好地捕捉序列的特征。 前面讲的图片或语言，都属于欧式空间..." }, { "title": "GCN", "url": "/posts/GCN/", "categories": "GNN", "tags": "GCN", "date": "2020-07-02 20:19:00 +0800", "snippet": "Graph Convolutional Networks(GCN): 图卷积神经网络，实际上跟CNN的作用类似，就是一个特征提取器，只不过它的对象是图数据。GCN精妙地设计了一种从图数据中提取特征的方法，从而让我们可以使用这些特征去对图数据进行：节点分类 、图分类、边预测，还可顺便得到图的嵌入表示。【图结构】之图神经网络GCN详解图卷积网络(Graph Convolutional Networks, GCN)详细介绍如何理解 Graph Convolutional Network（GCN）？" }, { "title": "GAT", "url": "/posts/GAT/", "categories": "GNN", "tags": "GAT", "date": "2020-07-02 20:19:00 +0800", "snippet": "GCN缺点： 模型对于同阶邻域上分配给不同邻居的权重是完全相同的（也就是GAT论文里说的：无法允许为邻居中的不同节点指定不同的权重）。这一点限制了模型对于空间信息的相关性的捕捉能力，这也是在很多任务上不如GAT的根本原因。 GCN结合临近节点特征的方式和图的结构依依相关，这局限了训练所得模型在其他图结构上的泛化能力。GAT提出了用注意力机制对邻近节点特征加权求和。邻近节点特征的权重完全取决于节点特征，独立于图结构。GAT和GCN的核心区别在于如何收集并累和距离为1的邻居节点的特征表示。图注意力模型GAT用注意力机制替代了GCN中固定的标准化操作。本质上，GAT只是将原本GCN的标准化..." }, { "title": "Tiling", "url": "/posts/tiling/", "categories": "AI", "tags": "Tiling", "date": "2020-07-02 20:19:00 +0800", "snippet": "Tiling在深度学习网络中，Conv, MatMul等操作都会降维为矩阵乘(GEMM)进行计算，业界的深度学习计算库如oneDNN、cuDNN等都对GEMM计算做了很多优化，其中最常见且通用的手段就是对于内存层级的tiling。Tiling的目的主要是为了满足芯片片上存储及计算流水线的需求，以最大化计算并行性和数据局部性，从而发挥硬件的极致性能。AI芯片内buffer size有限，参与一次AI CORE运算的输入输出数据量均是受限的，因此要做tiling，对大矩阵进行拆分，分块进行运算。举例： 矩阵A大小：M=256, K=192 矩阵B大小：K=192, N=192 Tili..." }, { "title": "超参", "url": "/posts/hyper_param/", "categories": "AI", "tags": "深度学习", "date": "2020-07-02 20:19:00 +0800", "snippet": " 深度学习的优化算法，说白了就是梯度下降。每次的参数更新有两种方式： 遍历全部数据集计算一次损失函数，然后算函数对各个参数的梯度，更新梯度。 这种方法每更新一次参数都要把数据集里的所有样本都看一遍，计算量开销大，计算速度慢，不支持在线学习，这称为Batch gradient descent，批梯度下降。 每看一个数据就算一下损失函数，然后求梯度更新参数，这个称为随机梯度下降，stochastic gradient descent。 这个方法速度比较快，但是收敛性能不太好，可能在最优点附近晃来晃去，hit不到最优点。两次..." }, { "title": "深度学习基础", "url": "/posts/foundation/", "categories": "AI", "tags": "AI", "date": "2020-07-02 20:19:00 +0800", "snippet": "目标函数 当任务在试图预测数值时，最常⻅的损失函数是平⽅误差(squared error)，即预测值与实际值之差的平⽅。 当试图解决分类问题时，最常⻅的⽬标函数是最小化错误率，我们通常将可⽤数据集分成两部分：训练数据集⽤于拟合模型参数，测试数据集⽤于评估拟合的模型。无监督学习数据中不含有“⽬标”的机器学习问题为⽆监督学习。例子 聚类 主成分分析 因果关系 概率图模型 生成对抗网络广播机制节约内存。" }, { "title": "Caffe", "url": "/posts/caffe/", "categories": "AI", "tags": "Caffe", "date": "2020-07-02 20:19:00 +0800", "snippet": "源码安装# 下载源码git clone https://github.com/BVLC/caffe.git# 根据当前环境基于模板修改Makefile.configcp Makefile.config.example Makefile.configvim Makefile.config# 用make编译caffe bin, 找不到的头文件, lib, 通过安装对应lib，修改Makefile.config解决make all -j8# 安装依赖的libsudo apt-get install libboost-devsudo apt-get install libgflags-devsu..." }, { "title": "CV", "url": "/posts/CV/", "categories": "AI", "tags": "CV", "date": "2020-07-02 20:19:00 +0800", "snippet": "深度学习经典目标检测方法 One-stage: YOLO系列 只有一步“回归”操作。 优点：速度非常快，适合做实时检测任务 缺点：效果通常不会太好 Two-stage: Faster-Rcnn，Mask-Rcnn系列 多了一步“预选”操作。 优点：效果通常不错； 缺点：速度通常较慢； mAP指标IoUIoU = Area of Overlap / Arrea of UnionArrea of Overlap: Groud truth 与prediction的交集Arrea of ..." }, { "title": "STL", "url": "/posts/stl/", "categories": "C++", "tags": "C++", "date": "2020-07-02 10:33:00 +0800", "snippet": "C++ STL STRING的COPY-ON-WRITE技术STL六大组件： 容器(Container)， 存放数据 分配器(Allocators)， “幕后英雄”， 为容器分配内存。allocator版本底层调用operator new, new调用malloc 迭代器(Iterators)，操作数据 算法(Algorithms)，操作数据的规则 适配器(Adapters), 比如deque,stack 仿函数(Functors)int main () { int ia[6] = {27, 210, 12,47,109,83}; vector&amp..." }, { "title": "读薄《Professional CUDA C Programming》——全局内存", "url": "/posts/cuda-c-chap04/", "categories": "CUDA", "tags": "GPU, CUDA", "date": "2020-07-01 20:19:00 +0800", "snippet": "四、全局内存本章将剖析核函数与全局内存的联系及其对性能的影响。本章将介绍CUDA内存模型， 并通过分析不同的全局内存访问模式来介绍如何通过核函数高效地利用全局内存。CUDA内存模型概述在现有的硬件存储子系统下，必须依靠内存模型获得最佳的延迟和带宽。CUDA内存模型结合了主机和设备的内存系统，展现了完整的内存层次结构，使你能显式地控制数据布局以优化性能。内存层次结构的优点一般来说，应用程序不会在某一时间点访问任意数据或运行任意代码。应用程序往往遵循局部性原则。有两种不同类型的局部性： 时间局部性：若一个数据被引用，那该数据在较短时间内很可能会再次被引用，随着时间流逝，该数据被引用的可能性..." }, { "title": "读薄《Professional CUDA C Programming》——CUDA执行模型", "url": "/posts/cuda-c-chap03/", "categories": "CUDA", "tags": "GPU, CUDA", "date": "2020-07-01 20:19:00 +0800", "snippet": "三、CUDA执行模型通过第二章的练习，已经了解了如何在网格和线程块中组织线程以获得最佳的性能。尽管可通过反复试验找到最佳的执行配置，但可能仍然会感到疑惑，为什么选择这样的执行配置会更好。你可能想知道是否有一些选择网格和块配置的准则。本章将回答这些问题， 并从硬件方面深入介绍内核启动配置和性能分析的信息。CUDA执行模型概述一般来说，执行模型会提供一个操作视图，说明如何在特定的计算架构上执行指令。CUDA执行模型揭示了GPU并行架构的抽象视图，使我们能够据此分析线程并发。CUDA执行模型能够提供有助于在指令吞吐量和内存访问方面编写高效代码的见解。GPU架构概述Streaming Multi..." }, { "title": "读薄《Professional CUDA C Programming》——CUDA编程模型", "url": "/posts/cuda-c-chap02/", "categories": "CUDA", "tags": "GPU, CUDA", "date": "2020-07-01 20:19:00 +0800", "snippet": "二、CUDA编程模型CUDA编程模型概述CUDA编程结构站在程序员的角度，可以从以下几个不同层面来看待并行计算： 领域层(Domain level) 逻辑层(Logic level) 硬件层(Hardware level)这三个层面对应了并行计算编程的不同阶段： 算法设计阶段，最关心的应是在领域层如何解析数据和函数，以便在并行环境中能正确、高效地解决问题。 编码阶段，关注点应转向如何组织并发线程。在这个阶段，需要从逻辑层面来思考，以确保线程和计算能正确地解决问题。在C语言并行编程中，需要使用pthreads或OpenMP技术来显式地管理线程。CUDA提出了一个线程层次结构抽象的..." }, { "title": "读薄《Professional CUDA C Programming》——基于CUDA的异构并行编程", "url": "/posts/cuda-c-chap01/", "categories": "CUDA", "tags": "GPU, CUDA", "date": "2020-07-01 20:19:00 +0800", "snippet": "一、基于CUDA的异构并行编程并行计算并行计算的主要目标是提高计算速度。并行计算的软件和硬件层面是紧密联系的，传说中的软硬件协同。并行计算通常涉及两个不同的计算技术领域： 计算机架构（硬件方面），关注的是在结构层次上支持并行性。 并行程序设计（软件方面），关注的是充分使用架构的计算能力来并发地解决问题。并行性在并行算法的实现中， 分析数据的相关性是最基本的内容， 因为相关性是限制并行性的一个主要因素。在应用程序中有两种基本的并行类型： 任务并行。重点在于利用多核系统对任务进行分配。 数据并行。重点在于利用多核系统对数据进行分配。数据并行程序设计的第一步是依据线程划分数据， 以使每..." }, { "title": "GPU", "url": "/posts/GPU/", "categories": "GPU", "tags": "GPU", "date": "2020-07-01 20:19:00 +0800", "snippet": "Hanlding cuda error messageshttp://cuda-programming.blogspot.com/2013/01/handling-cuda-error-messages.htmlvoid cuda_safe(cudaError_t error, char* message) { if (error != cudaSuccess) { printf(&quot;ERROR: %s : %i\\n&quot;, message, error); exit(-1); }}void Check_CUDA_Error(cons..." } ]
