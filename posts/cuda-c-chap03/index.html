<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="读薄《Professional CUDA C Programming》——CUDA执行模型" /><meta name="author" content="dazuo" /><meta property="og:locale" content="en_US" /><meta name="description" content="三、CUDA执行模型" /><meta property="og:description" content="三、CUDA执行模型" /><link rel="canonical" href="https://dazuozcy.github.io/posts/cuda-c-chap03/" /><meta property="og:url" content="https://dazuozcy.github.io/posts/cuda-c-chap03/" /><meta property="og:site_name" content="zuo" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-07-01T20:19:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="读薄《Professional CUDA C Programming》——CUDA执行模型" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"dazuo"},"dateModified":"2022-12-10T21:50:05+08:00","datePublished":"2020-07-01T20:19:00+08:00","description":"三、CUDA执行模型","headline":"读薄《Professional CUDA C Programming》——CUDA执行模型","mainEntityOfPage":{"@type":"WebPage","@id":"https://dazuozcy.github.io/posts/cuda-c-chap03/"},"url":"https://dazuozcy.github.io/posts/cuda-c-chap03/"}</script><title>读薄《Professional CUDA C Programming》——CUDA执行模型 | zuo</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="zuo"><meta name="application-name" content="zuo"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" as="script"> <script async src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://cdn.jsdelivr.net/gh/cotes2020/chirpy-images/commons/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">zuo</a></div><div class="site-subtitle font-italic">感谢永远有歌把心境道破</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/dazuozcy" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['dazuozcy','163.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>读薄《Professional CUDA C Programming》——CUDA执行模型</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>读薄《Professional CUDA C Programming》——CUDA执行模型</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> dazuo </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Jul 1, 2020, 8:19 PM +0800" prep="on" > Jul 1, 2020 <i class="unloaded">2020-07-01T20:19:00+08:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sat, Dec 10, 2022, 9:50 PM +0800" prefix="Updated " > Dec 10, 2022 <i class="unloaded">2022-12-10T21:50:05+08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="11927 words">66 min</span></div></div><div class="post-content"><h1 id="三cuda执行模型">三、CUDA执行模型</h1><p>通过第二章的练习，已经了解了如何<strong>在网格和线程块中组织线程</strong>以获得最佳的性能。尽管可通过反复试验找到最佳的执行配置，但可能仍然会感到疑惑，为什么选择这样的执行配置会更好。你可能想知道是否有一些选择网格和块配置的准则。本章将回答这些问题， 并从硬件方面深入介绍内核启动配置和性能分析的信息。</p><h2 id="cuda执行模型概述">CUDA执行模型概述</h2><p>一般来说，执行模型会提供一个操作视图，说明如何在特定的计算架构上执行指令。CUDA执行模型揭示了GPU并行架构的抽象视图，使我们能够据此分析线程并发。CUDA执行模型能够提供有助于在指令吞吐量和内存访问方面编写高效代码的见解。</p><h3 id="gpu架构概述">GPU架构概述</h3><p><code class="language-plaintext highlighter-rouge">Streaming Multiprocessors (SM)</code>，流式多处理器。GPU实际上是一个SM的阵列，每个SM包含N个真正执行计算的<code class="language-plaintext highlighter-rouge">Stream Processors(SP)</code>，也叫<code class="language-plaintext highlighter-rouge">Cuda Core</code>，能支持数百个线程并发执行。</p><p>下图说明了<code class="language-plaintext highlighter-rouge">Fermi SM</code>的关键组件：</p><ul><li>CUDA核心<li>寄存器文件<li>共享内存/一级缓存<li>加载/存储单元<li>特殊功能单元<li>线程束调度器</ul><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/fermi-sm.png" alt="cuda_exe_flow" width="1086" height="542" /></p><p>当启动一个kernel网格时， 它的线程块被分布在了可用的SM上来执行。 一个线程块只能在一个SM上被调度。 一旦线程块在一个SM上被调度， 就会保存在该SM上直到执行完成。 在同一时间， 一个SM可以容纳多个线程块，即多个线程块可能会被分配到同一SM上， 而且是根据SM资源的可用性进行调度的。</p><p>CUDA采用<strong>单指令多线程</strong>(<strong>SIMT</strong>) 架构来管理和执行线程，每<strong>32</strong>个线程为一组， 被称为<strong>线程束</strong>(<code class="language-plaintext highlighter-rouge">warp</code>)。线程束中的所有线程同时执行相同的指令。 每个线程都有自己的指令地址计数器和寄存器状态， 利用本线程自己的数据执行当前的指令。</p><blockquote><p>SIMT vs. SIMD</p></blockquote><p>两者都是将相同的指令广播给多个执行单元来实现并行。一个关键的区别是<code class="language-plaintext highlighter-rouge">SIMD</code>要求同一向量中的所有元素要在一个统一的同步组中一起执行，而<code class="language-plaintext highlighter-rouge">SIMT</code>允许同一线程束的多个线程独立执行。尽管一个线程束中的所有线程从相同的程序地址同时开始执行，但是单独的线程仍可能有不同的行为。 <code class="language-plaintext highlighter-rouge">SIMT</code>让你可以为独立的标量线程编写线程级并行代码，甚至为互相协作的线程编写数据并行的代码。</p><p><code class="language-plaintext highlighter-rouge">SIMT</code>模型包含3个<code class="language-plaintext highlighter-rouge">SIMD</code>所不具备的关键特征：</p><ul><li><p>每个线程有自己的指令地址计数器</p><li><p>每个线程有自己的寄存器状态</p><li><p>每个线程可以有一个独立的执行路径</p></ul><p>寄存器和共享内存是SM中的稀缺资源。这些有限的资源限制了在SM上活跃的线程束数量，活跃的线程束数量对应于SM上的并行量。</p><h3 id="fermi架构">Fermi架构</h3><p><code class="language-plaintext highlighter-rouge">Fermi</code>架构是第一个完整的GPU计算架构。下图所示为<code class="language-plaintext highlighter-rouge">Fermi</code>架构的逻辑框图。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/gpu-sm.png" alt="cuda_exe_flow" width="1086" height="542" /></p><p>CUDA核心被组织到<code class="language-plaintext highlighter-rouge">16</code>个SM中， 每一个SM含有<code class="language-plaintext highlighter-rouge">32</code>个CUDA核心。</p><p>每个CUDA核心都有一个全流水线的整数算术逻辑单元(ALU) 和一个浮点运算单元(FPU) ，在这里每个时钟周期执行一个整数或是浮点数指令。</p><p><code class="language-plaintext highlighter-rouge">Fermi</code>架构有6个384位的<code class="language-plaintext highlighter-rouge">GDDR5 DRAM</code>存储器接口，支持多达<code class="language-plaintext highlighter-rouge">6GB</code>的全局机载内存。</p><p><code class="language-plaintext highlighter-rouge">GigaThread</code>引擎是一个全局调度器，用来分配线程块到SM线程束调度器上。</p><p><code class="language-plaintext highlighter-rouge">Fermi</code>架构的一个关键特征是有一个<code class="language-plaintext highlighter-rouge">64KB</code>的片内可配置存储器，它在共享内存与一级缓存之间进行分配。</p><h3 id="kepler架构">Kepler架构</h3><p><code class="language-plaintext highlighter-rouge">Kepler</code> GPU架构是一种快速、高效、高性能的计算架构。<code class="language-plaintext highlighter-rouge">Kepler</code>的特点使得混合计算更容易。Kepler架构的3个重要的创新。</p><ul><li><p><strong>强化的SM</strong></p><p>每个Kepler SM单元包含192个单精度CUDA核心，64个双精度单元，32个特殊功能单元（SFU） 以及32个加载/存储单元（LD/ST）</p><li><p><strong>动态并行</strong></p><p>动态并行是Kepler GPU的一个新特性，它允许GPU动态启动新的网格。有了动态并行，任一内核都能启动其他的内核， 并且管理任何核间需要的依赖关系来正确地执行附加的工作，消除了与CPU通信的需求。动态并行拓宽了GPU在各种学科上的适用性。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/dynamic-parallelism.png" alt="cuda_exe_flow" width="1086" height="542" /></p><li><p><strong><code class="language-plaintext highlighter-rouge">Hyper-Q</code>技术</strong></p><p>Fermi GPU依赖一个单一的硬件工作队列来从CPU到GPU间传送任务，这可能会导致一个单独的任务阻塞队列中在该任务之后的所有其他任务。<code class="language-plaintext highlighter-rouge">Kepler </code>Hyper-Q<code class="language-plaintext highlighter-rouge">消除了这个限制。 如下图所示，Kepler GPU在主机与GPU之间提供了32个硬件工作队列。</code>Hyper-Q保证了在GPU上有更多的并发执行，最大限度地提高了GPU的利用，也减少了CPU的闲置时间，提高了整体的性能。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/hyper-q.png" alt="cuda_exe_flow" width="1086" height="542" /></p></ul><h3 id="profile驱动的优化">Profile驱动的优化</h3><p>性能分析工具深入洞察内核的性能， 检测核函数中影响性能的瓶颈。 CUDA提供了两个主要的性能分析工具： nvvp和nvprof。</p><ul><li><p><strong><code class="language-plaintext highlighter-rouge">nvvp</code></strong></p><p>独立的可视化分析器，它可以可视化并优化CUDA程序的性能。该工具会显示CPU与GPU上程序活动的时间表，从而找到可以改善性能的点。此外nvvp可以分析应用程序潜在的性能瓶颈，并给出消除或减少这些瓶颈的建议。该工具既可作为一个独立的应用程序，也可作为<code class="language-plaintext highlighter-rouge">Nsight Eclipse Edition(nsight)</code>的一部分。</p><li><p><strong><code class="language-plaintext highlighter-rouge">nvprof</code></strong></p><p>在命令行上收集和显示分析数据。<code class="language-plaintext highlighter-rouge">nvprof</code>是和CUDA 5一起发布的，它是从一个旧的命令行CUDA分析工具进化而来的。跟<code class="language-plaintext highlighter-rouge">nvvp</code>一样，它可获得CPU与GPU上CUDA关联活动的时间表，其中包括内核执行、内存传输和CUDA的API调用。它也可以获得硬件计数器和CUDA内核的性能指标。</p></ul><p>有3种常见的<strong>限制内核性能</strong>的因素：</p><ul><li>存储带宽<li>计算资源<li>指令和内存延迟</ul><h2 id="线程束执行的本质">线程束执行的本质</h2><p>启动内核时， 内核中所有的线程似乎都是并行地运行的，在逻辑上这是正确的， 但从硬件的角度来看， 不是所有线程在物理上都可以同时并行地执行。</p><h3 id="线程束和线程块">线程束和线程块</h3><p>线程束是<code class="language-plaintext highlighter-rouge">SM</code>中的基本执行单元。当一个<code class="language-plaintext highlighter-rouge">Grid</code>被启动后，<code class="language-plaintext highlighter-rouge">Grid</code>中的线程块分布在<code class="language-plaintext highlighter-rouge">SM</code>中。一旦线程块被调度到一个<code class="language-plaintext highlighter-rouge">SM</code>上，线程块中的线程会被进一步划分为<strong>线程束</strong>。一个线程束由<code class="language-plaintext highlighter-rouge">32</code>个连续的线程组成，一个线程束中所有的线程按照<code class="language-plaintext highlighter-rouge">SIMT</code>方式执行，即所有线程都执行相同的指令，每个线程在<strong>私有数据</strong>上进行操作。</p><p>如果线程块的大小不是线程束大小的偶数倍，那么最后的线程束里有些线程就不会活跃，即这些线程未被使用，但它们仍然消耗<code class="language-plaintext highlighter-rouge">SM</code>的资源，如寄存器。比如，某个线程块有<code class="language-plaintext highlighter-rouge">80</code>个线程，那么硬件会为这个线程块配置<code class="language-plaintext highlighter-rouge">80/32=3</code>个线程束，最后一个线程束的最后<code class="language-plaintext highlighter-rouge">16</code>个线程不会被使用。</p><h3 id="线程束分化">线程束分化</h3><p>一个线程束中的所有线程在同一周期中必须执行相同的指令，如果一个线程执行一条指令，那么线程束中的所有线程都必须执行该指令。如果在同一线程束中的线程使用不同的路径通过同一个应用程序，这可能会产生问题。一半的线程束需要执行if语句块中的指令，而另一半需要执行else语句块中的指令。<strong>在同一线程束中的线程执行不同的指令， 被称为线程束分化</strong>。</p><p>线程束分化会导致性能明显地下降。条件分支越多，并行性削弱越严重。</p><p>下面这个核函数是会产生线程束分化的例子，在同一个线程束里，不同线程有不同的路径。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">mathKernel1</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">c</span><span class="p">)</span> <span class="p">{</span>
	<span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
	<span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">;</span>
	<span class="n">a</span> <span class="o">=</span> <span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span><span class="n">f</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">a</span> <span class="o">=</span> <span class="mf">100.0</span><span class="n">f</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="n">b</span> <span class="o">=</span> <span class="mf">200.0</span><span class="n">f</span><span class="p">;</span>
	<span class="p">}</span>
	<span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;</span>
<span class="p">}</span>
</pre></table></code></div></div><p>下面这个核函数由于是按照线程束为粒度，所以不会产生线程束分化。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">mathKernel2</span><span class="p">(</span><span class="kt">void</span><span class="p">)</span> <span class="p">{</span>
	<span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
	<span class="kt">float</span> <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">;</span>
	<span class="n">a</span> <span class="o">=</span> <span class="n">b</span> <span class="o">=</span> <span class="mf">0.0</span><span class="n">f</span><span class="p">;</span>
	<span class="k">if</span> <span class="p">((</span><span class="n">tid</span> <span class="o">/</span> <span class="n">warpSize</span><span class="p">)</span> <span class="o">%</span> <span class="mi">2</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
		<span class="n">a</span> <span class="o">=</span> <span class="mf">100.0</span><span class="n">f</span><span class="p">;</span>
	<span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
		<span class="n">b</span> <span class="o">=</span> <span class="mf">200.0</span><span class="n">f</span><span class="p">;</span>
	<span class="p">}</span>
	<span class="n">c</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span> <span class="o">+</span> <span class="n">b</span><span class="p">;</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="资源分配">资源分配</h3><p>线程束的执行上下文主要由以下资源组成：</p><ul><li><p>程序计数器</p><li><p>寄存器</p><li><p>共享内存</p></ul><p>由于<strong>计算资源是在线程束之间进行分配的，而且在线程束的整个生存期中都保持在芯片内，因此线程束上下文的切换是非常快的</strong>。</p><p>对于一个给定的内核，同时存在于同一个<code class="language-plaintext highlighter-rouge">SM</code>中的线程块和线程束的数量取决于在<code class="language-plaintext highlighter-rouge">SM</code>中可用的且内核所需的寄存器和共享内存的数量。</p><p>资源可用性通常会限制SM中常驻线程块的数量。如果每个SM没有足够的寄存器或共享内存去处理至少一个块，那么内核将无法启动。</p><p>当计算资源已分配给线程块时，线程块被称为<strong>活跃的块</strong>。它所包含的线程束被称为<strong>活跃的线程束</strong>。活跃的线程束可以进一步被分为以下3种类型：</p><ul><li><p>选定的线程束：活跃执行的线程束</p><li><p><strong>阻塞的</strong>线程束：活跃的准备执行但尚未执行的线程束</p><li><p>符合条件的线程束：没有做好执行准备的线程束</p></ul><p>如果同时满足以下两个条件则线程束符合执行条件：</p><ul><li><p>32个CUDA核心可用于执行</p><li><p>当前指令中所有的参数都已就绪</p></ul><p>计算资源限制了活跃的线程束的数量。 为了最大程度地利用GPU， 需要最大化活跃的线程束数量。</p><h3 id="延迟隐藏">延迟隐藏</h3><p><strong>利用率</strong>与<strong>常驻线程束的数量</strong>直接相关。当每个时钟周期中所有的线程调度器都有一个符合条件的线程束时，可达到计算资源的完全利用。</p><p>指令可以被分为两种基本类型：</p><ul><li><p>算术指令，算术指令延迟是一个算术操作从开始到它产生输出之间的时间。为10～20个周期。</p><li><p>内存指令，内存指令延迟是指发送出的加载或存储操作和数据到达目的地之间的时间。全局内存访问为400～800个周期。</p></ul><blockquote><p>指令延迟： 在指令发出和完成之间的时钟周期</p></blockquote><h3 id="占用率">占用率</h3><p>占用率是每个SM中活跃的线程束占最大线程束数量的比值。</p><p>为了提高占用率，还需调整线程块配置或重新调整资源的使用情况，以允许更多的线程束同时处于活跃状态和提高计算资源的利用率。 极端地操纵线程块会限制资源的利用：</p><ul><li>小线程块：每个块中线程太少，会在所有资源被充分利用之前导致硬件达到每个SM的线程束数量的限制。<li>大线程块：每个块中有太多的线程，会导致在每个SM中每个线程可用的硬件资源较少。</ul><p><strong>网格和线程块大小的准则</strong>：</p><ul><li><p>保持每个块中线程数量是线程束大小(32)的倍数</p><li><p>避免块太小：<strong>每个块至少要有128或256个线程</strong></p><li><p>根据内核资源的需求调整块大小</p><li><p><strong>块的数量要远远多于SM的数量</strong>，从而在设备中可以显示有足够的并行</p><li><p>通过实验得到最佳执行配置和资源使用情况</p></ul><p>占用率唯一注重的是在每个SM中并发线程或线程束的数量。 然而，充分的占用率不是性能优化的唯一目标。内核一旦达到一定级别的占用率，进一步增加占用率可能不会改进性能。</p><h3 id="同步">同步</h3><p>在CUDA中，同步可以在两个级别执行：</p><ul><li><p><strong>系统级</strong>：等待主机和设备完成所有的工作</p><p>对于主机来说，许多CUDA API调用和所有的内核启动不是同步的，<code class="language-plaintext highlighter-rouge">cudaDeviceSynchronize()</code>可用来阻塞主机应用程序，直到所有的CUDA操作（复制、核函数等）完成。</p><li><p><strong>块级</strong>：在设备执行过程中等待一个线程块中所有线程到达同一点</p><p>当<code class="language-plaintext highlighter-rouge">__syncthreads()</code>被调用时，同一个线程块中的每个线程都必须等待直至该线程块中所有其他线程都已经达到这个同步点。在栅栏之前所有线程产生的所有全局内存和共享内存访问，将会在栅栏后对线程块中所有其他的线程可见。该函数可以协调同一个块中线程之间的通信，但它强制线程束空闲，从而可能对性能产生负面影响。</p></ul><p>线程块中的线程可以通过共享内存和寄存器来共享数据。在不同的块之间不允许线程同步。块间同步，唯一安全的方法是在每个内核执行结束端使用全局同步点； 也就是说，在全局同步之后，终止当前的核函数，开始执行新的核函数。</p><h3 id="可扩展性">可扩展性</h3><p>一个可扩展的并行程序可以高效地使用所有的计算资源以提高性能。可扩展性意味着增加的计算核心可以提高性能。 例如，若一个CUDA程序在两个SM中是可扩展的，则与在一个SM中运行相比，在两个SM中运行会使运行时间减半。能够在可变数量的计算核心上执行相同的应用程序代码的能力被称为<strong>透明可扩展性</strong>。</p><p>CUDA内核启动时，线程块分布在多个SM中。网格中的线程块以并行或连续或任意的顺序被执行。线程块执行的独立性质使得CUDA编程在任意数量的核心中都是可扩展的。独立性是基于不允许跨线程块同步，线程块可以以任何顺序、并行、串行的顺序在任何SM上执行。</p><h2 id="并行性的表现">并行性的表现</h2><p>为更好地理解线程束执行的本质，将使用不同的执行配置分析下述的<code class="language-plaintext highlighter-rouge">sumMatrixOnGPU2D</code>核函数。</p><div class="language-c++ highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">sumMatrixOnGPU2D</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">A</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">B</span><span class="p">,</span> <span class="kt">float</span> <span class="o">*</span><span class="n">C</span><span class="p">,</span> <span class="kt">int</span> <span class="n">NX</span><span class="p">,</span> <span class="kt">int</span> <span class="n">NY</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">ix</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">iy</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">y</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">y</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">iy</span> <span class="o">*</span> <span class="n">NX</span> <span class="o">+</span> <span class="n">ix</span><span class="p">;</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">ix</span> <span class="o">&lt;</span> <span class="n">NX</span> <span class="o">&amp;&amp;</span> <span class="n">iy</span> <span class="o">&lt;</span> <span class="n">NY</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">C</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">A</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">B</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="用nvprof检测活跃的线程束">用<code class="language-plaintext highlighter-rouge">nvprof</code>检测活跃的线程束</h3><p>一个内核的可实现占用率被定义为： 每周期内活跃线程束的平均数量与一个SM支持的线程束最大数量的比值。</p><p>可通过命令<code class="language-plaintext highlighter-rouge">nvprof --metrics achieved_occupancy xxx_exe</code>检测。</p><p>更高的占用率并不一定意味着有更高的性能。</p><h3 id="用nvprof检测内存操作">用nvprof检测内存操作</h3><p>可通过命令<code class="language-plaintext highlighter-rouge">nvprof --metrics gld_efficiency xxx_exe</code>检测。</p><p>可通过命令<code class="language-plaintext highlighter-rouge">nvprof --metrics gld_throughput xxx_exe</code>检测。</p><p>更高的加载吞吐量并不一定意味着更高的性能。</p><h3 id="增大并行性">增大并行性</h3><p>线程块最内层维度的大小对性能起着的关键的作用。</p><p>值得注意的是， 最好的执行配置既不具有最高的可实现占用率， 也不具有最高的加载吞吐量。</p><h2 id="避免分支分化">避免分支分化</h2><p>通过重新组织数据的获取模式， 可以减少或避免线程束分化。</p><h3 id="并行规约问题">并行规约问题</h3><p>在向量中执行满足交换律和结合律的运算，被称为<strong>归约问题</strong>。并行归约问题是这种运算的并行执行。并行归约是一种常见的并行模式，并且是许多并行算法中的一个关键运算。</p><p>根据每次迭代后<strong>输出元素就地存储的位置</strong>，成对的并行求和实现可以被进一步分为以下两种类型：</p><ul><li><p>相邻配对： 元素与它们直接相邻的元素配对。如下图所示</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/neighbored-pair.png" alt="cuda_exe_flow" width="1086" height="542" /></p><li><p>交错配对： 根据给定的跨度配对元素。如下图所示</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/Interleaved-pair.png" alt="cuda_exe_flow" width="1086" height="542" /></p></ul><h3 id="并行规约中的分化及改善">并行规约中的分化及改善</h3><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/neighbored-pair-impl1.png" alt="cuda_exe_flow" width="1086" height="542" /></p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceNeighbored</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// boundary check</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// in-place reduction in global memory</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&lt;</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span> <span class="n">stride</span> <span class="o">*=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
    	<span class="k">if</span> <span class="p">((</span><span class="n">tid</span> <span class="o">%</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">stride</span><span class="p">))</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    		<span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="n">stride</span><span class="p">];</span>
	    <span class="p">}</span>
    	<span class="c1">// synchronize within block</span>
    	<span class="n">__syncthreads</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/neighbored-pair-impl2.png" alt="cuda_exe_flow" width="1086" height="542" /></p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceNeighboredLess</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// boundary check</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// in-place reduction in global memory</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&lt;</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span> <span class="n">stride</span> <span class="o">*=</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="c1">// convert tid into local array index</span>
        <span class="kt">int</span> <span class="n">index</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">stride</span> <span class="o">*</span> <span class="n">tid</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">index</span> <span class="o">&lt;</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">)</span> <span class="p">{</span>
        	<span class="n">idata</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="n">stride</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="c1">// synchronize within threadblock</span>
        <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p>在上面第一张图的实现中，只有ID为偶数的线程执行这个条件语句的主体，但所有的线程都必须被调度。在第二次迭代中，只有四分之一的线程是活跃的，但是所有的线程仍然都必须被调度。通过重新组织每个线程的数组索引来强制ID相邻的线程执行求和操作，线程束分化就能被归约了，如上面第二张图所示。</p><h3 id="交错配对的规约">交错配对的规约</h3><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre><td class="rouge-code"><pre><span class="c1">/// Interleaved Pair Implementation with less divergence</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceInterleaved</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    
    <span class="c1">// boundary check</span>
    <span class="k">if</span><span class="p">(</span><span class="n">idx</span> <span class="o">&gt;=</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    	<span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// in-place reduction in global memory</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
    	<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
    		<span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="n">stride</span><span class="p">];</span>
    	<span class="p">}</span>
    	<span class="n">__syncthreads</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p>交错实现比相邻配对的第一个实现快了1.69倍，比第二个实现快了1.34倍。这种性能的提升主要是由kernel函数里的全局内存加载/存储模式导致的。</p><h2 id="循环展开">循环展开</h2><p>循环展开是一个尝试通过减少分支出现的频率和循环维护指令来优化循环的技术。循环体的复制数量被称为循环展开因子，迭代次数就变为了原始循环迭代次数除以循环展开因子。</p><p>在CUDA中，循环展开的意义非常重大。目标仍是相同的：通过减少指令消耗和增加更多独立调度指令来提高性能。因此，更多的并发操作被添加到流水线上，以产生更高的指令和内存带宽。这为线程束调度器提供更多符合条件的线程束，它们可帮助隐藏指令或内存延迟。</p><blockquote><p>当在CUDA中展开循环、 数据块或线程束时， 可以提高性能的两个主要原因是什么？ 解释每种展开是如何提升指令吞吐量的。</p></blockquote><p>Unrolling loops, data blocks, or warps can lead to less frequent branching from fewer loop conditionals. Additionally, unrolling can lead to an increase in the number of independent memory operations discoverable by the compiler. As a result, more concurrent read and write operations can be issued and memory bandwidth utilization will increase.</p><h3 id="展开的规约">展开的规约</h3><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceUnrolling2</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">2</span><span class="p">;</span>
    <span class="c1">// unrolling 2 data blocks</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="c1">// in-place reduction in global memory</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
        	<span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="n">stride</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="c1">// synchronize within threadblock</span>
        <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="展开线程束的规约">展开线程束的规约</h3><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceUnrollWarps8</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="mi">8</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="mi">8</span><span class="p">;</span>
    <span class="c1">// unrolling 8</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">7</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">6</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">7</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">a1</span><span class="o">+</span><span class="n">a2</span><span class="o">+</span><span class="n">a3</span><span class="o">+</span><span class="n">a4</span><span class="o">+</span><span class="n">b1</span><span class="o">+</span><span class="n">b2</span><span class="o">+</span><span class="n">b3</span><span class="o">+</span><span class="n">b4</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="c1">// in-place reduction in global memory</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">32</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">)</span> <span class="p">{</span>
            <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="n">stride</span><span class="p">];</span>
        <span class="p">}</span>
        <span class="c1">// synchronize within threadblock</span>
        <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// unrolling warp</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">volatile</span> <span class="kt">int</span> <span class="o">*</span><span class="n">vmem</span> <span class="o">=</span> <span class="n">idata</span><span class="p">;</span>
        <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">32</span><span class="p">];</span>
        <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">16</span><span class="p">];</span>
        <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">8</span><span class="p">];</span>
        <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">4</span><span class="p">];</span>
        <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">2</span><span class="p">];</span>
        <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="完全展开的规约">完全展开的规约</h3><p>如果编译时已知一个循环中的迭代次数， 就可以把循环完全展开。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceCompleteUnrollWarps8</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">8</span><span class="p">;</span>
    <span class="c1">// unrolling 8</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">7</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">7</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">a1</span> <span class="o">+</span> <span class="n">a2</span> <span class="o">+</span> <span class="n">a3</span> <span class="o">+</span> <span class="n">a4</span> <span class="o">+</span> <span class="n">b1</span> <span class="o">+</span> <span class="n">b2</span> <span class="o">+</span> <span class="n">b3</span> <span class="o">+</span> <span class="n">b4</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="c1">// in-place reduction and complete unroll</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">&gt;=</span><span class="mi">1024</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">512</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">512</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">&gt;=</span><span class="mi">512</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">256</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">256</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">&gt;=</span><span class="mi">256</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">128</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">&gt;=</span><span class="mi">128</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">64</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">64</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="c1">// unrolling warp</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">volatile</span> <span class="kt">int</span> <span class="o">*</span><span class="n">vsmem</span> <span class="o">=</span> <span class="n">idata</span><span class="p">;</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">32</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">16</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">8</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">4</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">2</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
    <span class="p">}</span>

    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="模板函数的规约">模板函数的规约</h3><p>使用模板函数有助于进一步减少分支消耗。如下所示，可以指定块的大小作为模板函数的参数。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
</pre><td class="rouge-code"><pre><span class="k">template</span> <span class="o">&lt;</span><span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">iBlockSize</span><span class="p">&gt;</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceCompleteUnroll</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">8</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">8</span><span class="p">;</span>
    <span class="c1">// unrolling 8</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">7</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">7</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">a1</span><span class="o">+</span><span class="n">a2</span><span class="o">+</span><span class="n">a3</span><span class="o">+</span><span class="n">a4</span><span class="o">+</span><span class="n">b1</span><span class="o">+</span><span class="n">b2</span><span class="o">+</span><span class="n">b3</span><span class="o">+</span><span class="n">b4</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="c1">// in-place reduction and complete unroll</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iBlockSize</span><span class="o">&gt;=</span><span class="mi">1024</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">512</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">512</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iBlockSize</span><span class="o">&gt;=</span><span class="mi">512</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">256</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">256</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iBlockSize</span><span class="o">&gt;=</span><span class="mi">256</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">128</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">128</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iBlockSize</span><span class="o">&gt;=</span><span class="mi">128</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">64</span><span class="p">)</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">64</span><span class="p">];</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="c1">// unrolling warp</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span> <span class="p">{</span>
        <span class="k">volatile</span> <span class="kt">int</span> <span class="o">*</span><span class="n">vsmem</span> <span class="o">=</span> <span class="n">idata</span><span class="p">;</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">32</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">16</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">8</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">4</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">2</span><span class="p">];</span>
        <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vsmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">1</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="p">}</span>
</pre></table></code></div></div><p>检查块大小的<code class="language-plaintext highlighter-rouge">if</code>语句将在编译时被评估，如果这一条件为<code class="language-plaintext highlighter-rouge">false</code>，那么编译时它将会被删除，使得内循环更有效率。该核函数一定要在<code class="language-plaintext highlighter-rouge">switch-case</code>结构中被调用。这允许编译器为特定的线程块大小自动优化代码，但这也意味着它只对在特定块大小下启动<code class="language-plaintext highlighter-rouge">reduceCompleteUnroll</code>有效。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</pre><td class="rouge-code"><pre><span class="k">switch</span> <span class="p">(</span><span class="n">blocksize</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">case</span> <span class="mi">1024</span><span class="p">:</span>
        <span class="n">reduceCompleteUnroll</span><span class="o">&lt;</span><span class="mi">1024</span><span class="o">&gt;&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_idata</span><span class="p">,</span> <span class="n">d_odata</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">case</span> <span class="mi">512</span><span class="p">:</span>
        <span class="n">reduceCompleteUnroll</span><span class="o">&lt;</span><span class="mi">512</span><span class="o">&gt;&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_idata</span><span class="p">,</span> <span class="n">d_odata</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">case</span> <span class="mi">256</span><span class="p">:</span>
        <span class="n">reduceCompleteUnroll</span><span class="o">&lt;</span><span class="mi">256</span><span class="o">&gt;&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_idata</span><span class="p">,</span> <span class="n">d_odata</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">case</span> <span class="mi">128</span><span class="p">:</span>
        <span class="n">reduceCompleteUnroll</span><span class="o">&lt;</span><span class="mi">128</span><span class="o">&gt;&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_idata</span><span class="p">,</span> <span class="n">d_odata</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
    <span class="k">case</span> <span class="mi">64</span><span class="p">:</span>
        <span class="n">reduceCompleteUnroll</span><span class="o">&lt;</span><span class="mi">64</span><span class="o">&gt;&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="o">/</span><span class="mi">8</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_idata</span><span class="p">,</span> <span class="n">d_odata</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
        <span class="k">break</span><span class="p">;</span>
<span class="p">}</span>
</pre></table></code></div></div><h3 id="总结">总结</h3><p>在上面几种展开方式中，最大的相对性能增益是通过<code class="language-plaintext highlighter-rouge">reduceUnrolling8</code>核函数获得的，在这个函数之中每个线程在归约前处理8个数据块。有了8个独立的内存访问，可以更好地让内存带宽饱和及隐藏加载/存储延迟。</p><h2 id="动态并行">动态并行</h2><p>CUDA的动态并行允许在GPU端直接创建和同步新的GPU内核。这使得可以在一个核函数中任意点动态增加GPU应用程序的并行性。</p><p>动态并行提供了一个更有层次结构的方法， 在这个方法中， 并发性可以在一个GPU内核的多个级别中表现出来。</p><p>使用动态并行可以让递归算法更加清晰易懂， 也更容易理解。</p><p>有了动态并行， 可推迟到运行时决定要在GPU上创建多少个块和网格， 可以动态地利用GPU硬件调度器和加载平衡器， 并进行调整以适应数据驱动或工作负载。</p><p>在GPU端直接创建工作的能力可以减少在主机和设备之间传输执行控制和数据的需求。</p><h3 id="嵌套执行">嵌套执行</h3><p>在动态并行中，内核执行分为两种类型：<strong>父母</strong>和<strong>孩子</strong>。</p><ul><li>父线程、父线程块或父网格启动一个新的网格（子网格）。<li>子线程、子线程块或子网格被父母启动。子网格必须在父线程、父线程块或父网格完成之前完成。<li>只有在所有的子网格都完成之后，父母才会完成。</ul><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/parent-child-grid.png" alt="cuda_exe_flow" width="1086" height="542" /></p><p>上图中，主机线程配置和启动父网格，父网格配置和启动子网格。子网格的调用和完成必须进行适当地嵌套，这意味着在线程创建的所有子网格都完成之后，父网格才会完成。如果调用的线程没有显式地同步启动子网格，那么运行时保证父母和孩子之间的隐式同步。上图中，在父线程中设置了栅栏，从而可以与其子网格显式地同步。</p><p>设备线程中的网格启动，在线程块间是可见的。这意味着线程可能与由该线程启动的或由相同线程块中其他线程启动的子网格同步。在线程块中，只有当所有线程创建的所有子网格完成之后，线程块的执行才会完成。如果块中所有线程在所有的子网格完成之前退出，那么在那些子网格上隐式同步会被触发。</p><p>当父母启动一个子网格，父线程块与孩子显式同步之后，孩子才能开始执行。</p><p>父网格和子网格<strong>共享全局和常量内存</strong>，但它们有不同的局部内存和共享内存。有了<strong>孩子和父母之间的弱一致性</strong>作为保证，父网格和子网格可以对全局内存并发存取。有两个时刻，子网格和它的父线程见到的内存完全相同：<strong>子网格开始时</strong>和<strong>子网格完成时</strong>。当父线程优于子网格调用时，所有的全局内存操作要保证对子网格是可见的。当父母在子网格完成时进行同步操作后，子网格所有的内存操作应保证对父母是可见的。</p><p>共享内存和局部内存分别对于线程块或线程来说是私有的，同时，在父母和孩子之间不是可见或一致的。局部内存对线程来说是私有存储，并且对该线程外部不可见。当启动一个子网格时，向局部内存传递一个指针作为参数是无效的。</p><h3 id="gpu上嵌套的hello-world">GPU上嵌套的Hello World</h3><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/nested-hello-world.png" alt="cuda_exe_flow" width="1086" height="542" /></p><p>上图说明了用动态并行由这个核函数构造的嵌套、递归执行。主机应用程序调用父网格，该父网格在一个线程块中有8个线程。然后该父网格中的线程0调用一个子网格，该子网格中有4个线程。之后，第一个子网格中的线程0再调用一个新的子网格，这个新的子网格中也只有一半线程，即2个线程，以此类推，直到最后的嵌套中只剩下一个线程。实现代码如下：</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">nestedHelloWorld</span><span class="p">(</span><span class="kt">int</span> <span class="k">const</span> <span class="n">iSize</span><span class="p">,</span><span class="kt">int</span> <span class="n">iDepth</span><span class="p">)</span> <span class="p">{</span>
    <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Recursion=%d: Hello World from thread %d block %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">iDepth</span><span class="p">,</span><span class="n">tid</span><span class="p">,</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
    <span class="c1">// condition to stop recursive execution</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iSize</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>
    <span class="c1">// reduce block size to half</span>
    <span class="kt">int</span> <span class="n">nthreads</span> <span class="o">=</span> <span class="n">iSize</span><span class="o">&gt;&gt;</span><span class="mi">1</span><span class="p">;</span>
    <span class="c1">// thread 0 launches child grid recursively</span>
    <span class="k">if</span><span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">nthreads</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">nestedHelloWorld</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">nthreads</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">nthreads</span><span class="p">,</span><span class="o">++</span><span class="n">iDepth</span><span class="p">);</span>
    	<span class="n">printf</span><span class="p">(</span><span class="s">"-------&gt; nested execution depth: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span><span class="n">iDepth</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p>因为动态并行是由设备运行时库所支持的，所以<code class="language-plaintext highlighter-rouge">nestedHelloWorld</code>函数必须在命令行使用<code class="language-plaintext highlighter-rouge">-lcudadevrt</code>进行明确链接。当<code class="language-plaintext highlighter-rouge">-rdc</code>标志为<code class="language-plaintext highlighter-rouge">true</code>时，它强制生成可重定位的设备代码，这是动态并行的一个要求。编译命令及输出效果如下所示：(<code class="language-plaintext highlighter-rouge">-arch=sm_35</code>是因为递归调用仅支持compute_35及以上的架构)</p><div class="language-shell highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
</pre><td class="rouge-code"><pre><span class="nv">$ </span>nvcc <span class="nt">-arch</span><span class="o">=</span>sm_35 <span class="nt">-rdc</span><span class="o">=</span><span class="nb">true </span>nestedHelloWorld.cu <span class="nt">-o</span> nestedHelloWorld <span class="nt">-lcudadevrt</span>

<span class="nv">$ </span>./nestedHelloWorld Execution Configuration: grid 1 block 8
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 0 block 0
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 1 block 0
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 2 block 0
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 3 block 0
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 4 block 0
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 5 block 0
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 6 block 0
<span class="nv">Recursion</span><span class="o">=</span>0: Hello World from thread 7 block 0
<span class="nt">-------</span><span class="o">&gt;</span> nested execution depth: 1
<span class="nv">Recursion</span><span class="o">=</span>1: Hello World from thread 0 block 0
<span class="nv">Recursion</span><span class="o">=</span>1: Hello World from thread 1 block 0
<span class="nv">Recursion</span><span class="o">=</span>1: Hello World from thread 2 block 0
<span class="nv">Recursion</span><span class="o">=</span>1: Hello World from thread 3 block 0
<span class="nt">-------</span><span class="o">&gt;</span> nested execution depth: 2
<span class="nv">Recursion</span><span class="o">=</span>2: Hello World from thread 0 block 0
<span class="nv">Recursion</span><span class="o">=</span>2: Hello World from thread 1 block 0
<span class="nt">-------</span><span class="o">&gt;</span> nested execution depth: 3
<span class="nv">Recursion</span><span class="o">=</span>3: Hello World from thread 0 block 0
</pre></table></code></div></div><p>使用2个线程块启动父网络有2种策略：</p><ul><li><p>策略1</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/child-grids-launch-1.png" alt="cuda_exe_flow" width="1086" height="542" /></p><li><p>策略2，这种启动策略产生的子网络数量更少</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/child-grids-launch-2.png" alt="cuda_exe_flow" width="1086" height="542" /></p></ul><h3 id="嵌套规约">嵌套规约</h3><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpuRecursiveReduce</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">isize</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">odata</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
    <span class="c1">// stop condition</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">isize</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">idata</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
    	<span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// nested invocation</span>
    <span class="kt">int</span> <span class="n">istride</span> <span class="o">=</span> <span class="n">isize</span><span class="o">&gt;&gt;</span><span class="mi">1</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">istride</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="n">istride</span><span class="p">)</span> <span class="p">{</span>
    	<span class="c1">// in place reduction</span>
    	<span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="n">istride</span><span class="p">];</span>
    <span class="p">}</span>
    <span class="c1">// sync at block level</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="c1">// nested invocation to generate child grids</span>
    <span class="k">if</span><span class="p">(</span><span class="n">tid</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">gpuRecursiveReduce</span> <span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">istride</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span><span class="n">odata</span><span class="p">,</span><span class="n">istride</span><span class="p">);</span>
    	<span class="c1">// sync all child grids launched in this block</span>
    	<span class="n">cudaDeviceSynchronize</span><span class="p">();</span>
    <span class="p">}</span>
    <span class="c1">// sync at block level again</span>
    <span class="n">__syncthreads</span><span class="p">();</span>
<span class="p">}</span>
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">gpuRecursiveReduce</code>的第一步是将全局内存地址<code class="language-plaintext highlighter-rouge">g_idata</code>转换为每个线程块的本地地址。接着，如果满足停止条件（这是指如果该条件是嵌套执行树上的叶子），结果就被拷贝回全局内存，并且控制立刻返回到父内核中。如果它不是一片叶子内核，就需要计算本地归约的大小，一半的线程执行就地归约。在就地归约完成后，同步线程块以保证所有部分和的计算。紧接着，线程0产生一个只有一个线程块和一个当前线程块一半线程数量的子网格。在子网格被调用后，所有子网格会设置一个障碍点。因为在每个线程块里，一个线程只产生一个子网格，所以这个障碍点只会同步一个子网格。</p><p>当一个子网格被调用后，它看到的内存与父线程是完全一样的。因为每一个子线程只需要父线程的数值来指导部分归约，所以在每个子网格启动前执行线程块内部的同步是没有必要的。去除所有同步操作会产生如下的核函数<code class="language-plaintext highlighter-rouge">gpuRecursiveReduceNosync</code>：</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpuRecursiveReduceNosync</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">isize</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">odata</span> <span class="o">=</span> <span class="o">&amp;</span><span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
    <span class="c1">// stop condition</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">isize</span> <span class="o">==</span> <span class="mi">2</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">idata</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
    	<span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// nested invoke</span>
    <span class="kt">int</span> <span class="n">istride</span> <span class="o">=</span> <span class="n">isize</span><span class="o">&gt;&gt;</span><span class="mi">1</span><span class="p">;</span>
    <span class="k">if</span><span class="p">(</span><span class="n">istride</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">tid</span> <span class="o">&lt;</span> <span class="n">istride</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="n">istride</span><span class="p">];</span>
    	<span class="k">if</span><span class="p">(</span><span class="n">tid</span><span class="o">==</span><span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">gpuRecursiveReduceNosync</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">istride</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">idata</span><span class="p">,</span><span class="n">odata</span><span class="p">,</span><span class="n">istride</span><span class="p">);</span>
    	<span class="p">}</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p><code class="language-plaintext highlighter-rouge">gpuRecursiveReduceNosync</code>相较于相邻配对内核的性能仍然很差。需要考虑如何减少由大量的子网格启动引起的消耗。在当前的实现中，每个线程块产生一个子网格，并且引起了大量的调用。如果使用了前面策略2所示图的方法，当创建的子网格数量减少时，那么每个子网格中线程块的数量将会增加， 以保持相同数量的并行性。</p><p>以下的核函数<code class="language-plaintext highlighter-rouge">gpuRecursiveReduce2</code>实现了这种方法：网格中第一个线程块中的第一个线程在每一步嵌套时都调用子网格。比较这两个核函数，会发现多了一个参数。因为每次嵌套调用时，子线程块大小会减到其父线程块大小的一半，父线程块的维度也必须传递给嵌套的子网格。这使得每个线程都能为它的工作负载部分正确计算出消耗部分的全局内存偏移地址。值得注意的是，在这个实现中，所有空闲的线程都是在每次内核启动时被移除的，而对于第一次实现而言，在每个嵌套层的内核执行过程中都会有一半的线程空闲下来。这样的改变将会释放一半的被第一个核函数消耗的计算资源，这样可以让更多的线程块活跃起来。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">gpuRecursiveReduce2</span><span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">int</span> <span class="n">iStride</span><span class="p">,</span> <span class="kt">int</span> <span class="k">const</span> <span class="n">iDim</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="o">*</span><span class="n">iDim</span><span class="p">;</span>
    <span class="c1">// stop condition</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iStride</span> <span class="o">==</span> <span class="mi">1</span> <span class="o">&amp;&amp;</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="n">idata</span><span class="p">[</span><span class="mi">1</span><span class="p">];</span>
    	<span class="k">return</span><span class="p">;</span>
    <span class="p">}</span>
    <span class="c1">// in place reduction</span>
    <span class="n">idata</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">iStride</span><span class="p">];</span>
    <span class="c1">// nested invocation to generate child grids</span>
    <span class="k">if</span><span class="p">(</span><span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
    	<span class="n">gpuRecursiveReduce2</span> <span class="o">&lt;&lt;&lt;</span><span class="n">gridDim</span><span class="p">.</span><span class="n">x</span><span class="p">,</span><span class="n">iStride</span><span class="o">/</span><span class="mi">2</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">g_idata</span><span class="p">,</span><span class="n">g_odata</span><span class="p">,</span><span class="n">iStride</span><span class="o">/</span><span class="mi">2</span><span class="p">,</span><span class="n">iDim</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>
</pre></table></code></div></div><p><strong>总结</strong></p><p>对于一个给定的算法，通过使用不同的动态并行技术，可以有多种可能的实现方式。避免大量嵌套调用有助于减少消耗并提升性能。同步对性能与正确性都至关重要，但减少线程块内部的同步次数可能会使嵌套内核效率更高。因为在每一个嵌套层上设备运行时系统都要保留额外的内存，所以内核嵌套的最大数量可能是受限制的。这种限制的程度依赖于内核，也可能会限制任何使用动态并行应用程序的扩展、性能以及其他的性能。</p><h2 id="习题">习题</h2><h3 id="1">1</h3><p><strong>当在CUDA中展开循环、 数据块或线程束时， 可以提高性能的两个主要原因是什么？ 解释每种展开是如何提升指令吞吐量的</strong>。</p><blockquote><ul><li>减少了循环次数，导致更少的分支预测。<li>增加了能被编译器识别的独立内存操作的数量</ul><p>最终，可以并发更多的读写操作，增加带宽利用率。</p></blockquote><h3 id="2">2</h3><p><strong>参考核函数<code class="language-plaintext highlighter-rouge">reduceUnrolling8</code>实现核函数<code class="language-plaintext highlighter-rouge">reduceUnrolling16</code>，在这个函数中每个线程处理16个数据块。将该函数的性能与<code class="language-plaintext highlighter-rouge">reduceUnrolling8</code>内核性能进行比较，通过nvprof使用合适的指标与事件来解释性能差异</strong>。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
</pre><td class="rouge-code"><pre><span class="n">__global__</span> <span class="kt">void</span> <span class="nf">reduceUnrolling16</span> <span class="p">(</span><span class="kt">int</span> <span class="o">*</span><span class="n">g_idata</span><span class="p">,</span> <span class="kt">int</span> <span class="o">*</span><span class="n">g_odata</span><span class="p">,</span> <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">n</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// set thread ID</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="kt">unsigned</span> <span class="kt">int</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">16</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>

    <span class="c1">// convert global data pointer to the local pointer of this block</span>
    <span class="kt">int</span> <span class="o">*</span><span class="n">idata</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="mi">16</span><span class="p">;</span>

    <span class="c1">// unrolling 16</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">15</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">&lt;</span> <span class="n">n</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="kt">int</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">2</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">a4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">3</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">4</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">6</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">b4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">7</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">c1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">8</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">c2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">9</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">c3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">10</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">c4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">11</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">d1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">12</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">d2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">13</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">d3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">14</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="kt">int</span> <span class="n">d4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span> <span class="o">+</span> <span class="mi">15</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
        <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">a1</span> <span class="o">+</span> <span class="n">a2</span> <span class="o">+</span> <span class="n">a3</span> <span class="o">+</span> <span class="n">a4</span> <span class="o">+</span> <span class="n">b1</span> <span class="o">+</span> <span class="n">b2</span> <span class="o">+</span> <span class="n">b3</span> <span class="o">+</span> <span class="n">b4</span> <span class="o">+</span> <span class="n">c1</span> <span class="o">+</span> <span class="n">c2</span> <span class="o">+</span> <span class="n">c3</span> <span class="o">+</span> <span class="n">c4</span>
                       <span class="o">+</span> <span class="n">d1</span> <span class="o">+</span> <span class="n">d2</span> <span class="o">+</span> <span class="n">d3</span> <span class="o">+</span> <span class="n">d4</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">__syncthreads</span><span class="p">();</span>

    <span class="c1">// in-place reduction in global memory</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">;</span> <span class="n">stride</span> <span class="o">&gt;&gt;=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">)</span>
        <span class="p">{</span>
            <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="n">stride</span><span class="p">];</span>
        <span class="p">}</span>

        <span class="c1">// synchronize within threadblock</span>
        <span class="n">__syncthreads</span><span class="p">();</span>
    <span class="p">}</span>

    <span class="c1">// write result for this block to global mem</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="n">g_odata</span><span class="p">[</span><span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">]</span> <span class="o">=</span> <span class="n">idata</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>
<span class="p">}</span>
</pre></table></code></div></div><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
</pre><td class="rouge-code"><pre><span class="c1">// kernel 7: reduceUnrolling16</span>
<span class="n">CHECK</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">d_idata</span><span class="p">,</span> <span class="n">h_idata</span><span class="p">,</span> <span class="n">bytes</span><span class="p">,</span> <span class="n">cudaMemcpyHostToDevice</span><span class="p">));</span>
<span class="n">CHECK</span><span class="p">(</span><span class="n">cudaDeviceSynchronize</span><span class="p">());</span>
<span class="n">iStart</span> <span class="o">=</span> <span class="n">seconds</span><span class="p">();</span>
<span class="n">reduceUnrolling16</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">16</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">d_idata</span><span class="p">,</span> <span class="n">d_odata</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
<span class="n">CHECK</span><span class="p">(</span><span class="n">cudaDeviceSynchronize</span><span class="p">());</span>
<span class="n">iElaps</span> <span class="o">=</span> <span class="n">seconds</span><span class="p">()</span> <span class="o">-</span> <span class="n">iStart</span><span class="p">;</span>
<span class="n">CHECK</span><span class="p">(</span><span class="n">cudaMemcpy</span><span class="p">(</span><span class="n">h_odata</span><span class="p">,</span> <span class="n">d_odata</span><span class="p">,</span> <span class="n">grid</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">16</span> <span class="o">*</span> <span class="nf">sizeof</span><span class="p">(</span><span class="kt">int</span><span class="p">),</span>
                 <span class="n">cudaMemcpyDeviceToHost</span><span class="p">));</span>
<span class="n">gpu_sum</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>

<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">grid</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">16</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="n">gpu_sum</span> <span class="o">+=</span> <span class="n">h_odata</span><span class="p">[</span><span class="n">i</span><span class="p">];</span>

<span class="n">printf</span><span class="p">(</span><span class="s">"gpu Unrolling16 elapsed %f sec gpu_sum: %d &lt;&lt;&lt;grid %d block "</span>
       <span class="s">"%d&gt;&gt;&gt;</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">iElaps</span><span class="p">,</span> <span class="n">gpu_sum</span><span class="p">,</span> <span class="n">grid</span><span class="p">.</span><span class="n">x</span> <span class="o">/</span> <span class="mi">16</span><span class="p">,</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>
</pre></table></code></div></div><p>在<code class="language-plaintext highlighter-rouge">Tesla V100</code>上，<code class="language-plaintext highlighter-rouge">reduceUnrolling16</code>比<code class="language-plaintext highlighter-rouge">reduceUnrolling8</code>的性能更好，但是不明显。</p><h3 id="3">3</h3><p><strong>参考核函数<code class="language-plaintext highlighter-rouge">reduceUnrolling8</code>， 将以下的代码段：</strong></p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
</pre><td class="rouge-code"><pre><span class="kt">int</span> <span class="n">a1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">a2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">a3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">a4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">3</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">b1</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">4</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">b2</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">5</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">b3</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">6</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="kt">int</span> <span class="n">b4</span> <span class="o">=</span> <span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="o">+</span><span class="mi">7</span><span class="o">*</span><span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">];</span>
<span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">a1</span><span class="o">+</span><span class="n">a2</span><span class="o">+</span><span class="n">a3</span><span class="o">+</span><span class="n">a4</span><span class="o">+</span><span class="n">b1</span><span class="o">+</span><span class="n">b2</span><span class="o">+</span><span class="n">b3</span><span class="o">+</span><span class="n">b4</span><span class="p">;</span>
</pre></table></code></div></div><p><strong>替换成如下代码段</strong></p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre><span class="kt">int</span> <span class="o">*</span><span class="n">ptr</span> <span class="o">=</span> <span class="n">g_idata</span> <span class="o">+</span> <span class="n">idx</span><span class="p">;</span>
<span class="kt">int</span> <span class="n">tmp</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
<span class="c1">// Increment tmp 8 times with values strided by blockDim.x</span>
<span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">8</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
	<span class="n">tmp</span> <span class="o">+=</span> <span class="o">*</span><span class="n">ptr</span><span class="p">;</span> <span class="n">ptr</span> <span class="o">+=</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
<span class="p">}</span>
<span class="n">g_idata</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">tmp</span><span class="p">;</span>
</pre></table></code></div></div><p><strong>比较每次的性能并解释使用<code class="language-plaintext highlighter-rouge">nvprof</code>指标的差异。</strong></p><blockquote><ul><li><p>寄存器使用情况</p><p><code class="language-plaintext highlighter-rouge">nvcc -O2 -Xptxas="-v" reduceInteger-8-new.cu</code></p><p>origin: used 25 registers</p><p>new: used 23 registers</p><li><p>achieved_occupancy</p><p><code class="language-plaintext highlighter-rouge">nvprof --metrics achieved_occupancy ./a.out</code></p><p>origin: 0.952788</p><p>new: 0.955784</p><li><p>global load/store transactions</p><p><code class="language-plaintext highlighter-rouge">nvprof --metrics gld_transactions,gst_transactions ./a.out</code></p><p>origin: gld_transactions:2641920, gst_transactions:536576</p><p>new: gld_transactions:2641920, gst_transactions:536576</p><li><p>global load/store efficiency</p><p><code class="language-plaintext highlighter-rouge">nvprof --metrics gld_efficiency,gst_efficiency ./a.out</code></p><p>origin: gld_efficiency:99.21%, gst_efficiency:97.71%</p><p>new: gld_efficiency:99.21%, gst_efficiency:97.71%</p><p>global load/store throughput</p><p><code class="language-plaintext highlighter-rouge">nvprof --metrics gld_throughput,gst_throughput ./a.out</code></p><p>origin: gld_throughput:718.53 GB/s, gst_throughput:145.53 GB/s</p><p>new: gld_throughput:729.53 GB/s, gst_throughput:148.53 GB/s</p></ul></blockquote><h3 id="4">4</h3><p><strong>参考核函数<code class="language-plaintext highlighter-rouge">reduceCompleteUnrollWarps8</code>。不要将<code class="language-plaintext highlighter-rouge">vmem</code>声明为<code class="language-plaintext highlighter-rouge">volatile</code>修饰符，而是使用<code class="language-plaintext highlighter-rouge">__syncthreads</code>。注意<code class="language-plaintext highlighter-rouge">__syncthreads</code>必须被线程块里的所有线程调用。比较两个核函数的性能并使用<code class="language-plaintext highlighter-rouge">nvprof</code>来解释所有的差异</strong>。</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre><td class="rouge-code"><pre><span class="c1">// unrolling warp</span>
<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span>
<span class="p">{</span>
    <span class="k">volatile</span> <span class="kt">int</span> <span class="o">*</span><span class="n">vmem</span> <span class="o">=</span> <span class="n">idata</span><span class="p">;</span>
    <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">32</span><span class="p">];</span>
    <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">16</span><span class="p">];</span>
    <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">8</span><span class="p">];</span>
    <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">4</span><span class="p">];</span>
    <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">2</span><span class="p">];</span>
    <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">vmem</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">1</span><span class="p">];</span>
<span class="p">}</span>
</pre></table></code></div></div><p>将上面的代码片段改成如下所示：</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
</pre><td class="rouge-code"><pre><span class="c1">// unrolling warp</span>
<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">32</span><span class="p">];</span>
<span class="n">__syncthreads</span><span class="p">();</span>

<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span> <span class="mi">16</span><span class="p">];</span>
<span class="n">__syncthreads</span><span class="p">();</span>

<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">8</span><span class="p">];</span>
<span class="n">__syncthreads</span><span class="p">();</span>

<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">4</span><span class="p">];</span>
<span class="n">__syncthreads</span><span class="p">();</span>

<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">2</span><span class="p">];</span>
<span class="n">__syncthreads</span><span class="p">();</span>

<span class="k">if</span> <span class="p">(</span><span class="n">tid</span> <span class="o">&lt;</span> <span class="mi">32</span><span class="p">)</span>
    <span class="n">idata</span><span class="p">[</span><span class="n">tid</span><span class="p">]</span> <span class="o">+=</span> <span class="n">idata</span><span class="p">[</span><span class="n">tid</span> <span class="o">+</span>  <span class="mi">1</span><span class="p">];</span>
</pre></table></code></div></div><blockquote><p>最重要的是意识到：如果将指针变量<code class="language-plaintext highlighter-rouge">vmem</code>声明为<code class="language-plaintext highlighter-rouge">volatile</code>，那么使用到该指针的<code class="language-plaintext highlighter-rouge">load</code>和<code class="language-plaintext highlighter-rouge">store</code>操作都会受到影响；然而，<code class="language-plaintext highlighter-rouge">__syncthreads</code> 仅保证同一个线程块里的其他线程对<code class="language-plaintext highlighter-rouge">global memory</code>做的修改对于该线程块的所有线程是可见的。</p><p>将<code class="language-plaintext highlighter-rouge">vmem</code>声明为<code class="language-plaintext highlighter-rouge">volatile</code>后，用该指针进行的所有load操作将会跳过L1 cache而直接从global memory中进行访问。</p><p>当使用__syncthreads代替后，load操作仍然会命中L1 cache，因为它是整个线程块共享的。</p><p>可以通过以下metrics验证上述内容：</p><p>Fermi/Kepler: l1_cache_global_hit_rate</p><p>Tesla: global_hit_rate</p></blockquote><h3 id="5">5</h3><p><strong>用C语言实现浮点数的求和归约</strong>。</p><blockquote><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
</pre><td class="rouge-code"><pre><span class="cp">#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;stdlib.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;sys/time.h&gt;</span><span class="cp">
</span>
<span class="kr">inline</span> <span class="kt">double</span> <span class="nf">seconds</span><span class="p">()</span>
<span class="p">{</span>
    <span class="k">struct</span> <span class="nc">timeval</span> <span class="n">tp</span><span class="p">;</span>
    <span class="k">struct</span> <span class="nc">timezone</span> <span class="n">tzp</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="n">gettimeofday</span><span class="p">(</span><span class="o">&amp;</span><span class="n">tp</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">tzp</span><span class="p">);</span>
    <span class="k">return</span> <span class="p">((</span><span class="kt">double</span><span class="p">)</span><span class="n">tp</span><span class="p">.</span><span class="n">tv_sec</span> <span class="o">+</span> <span class="p">(</span><span class="kt">double</span><span class="p">)</span><span class="n">tp</span><span class="p">.</span><span class="n">tv_usec</span> <span class="o">*</span> <span class="mf">1.e-6</span><span class="p">);</span>
<span class="p">}</span>

<span class="c1">// Recursive Implementation of Interleaved Pair Approach</span>
<span class="kt">float</span> <span class="nf">recursiveReduce</span><span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="n">data</span><span class="p">,</span> <span class="kt">int</span> <span class="k">const</span> <span class="n">size</span><span class="p">)</span>
<span class="p">{</span>
    <span class="c1">// terminate check</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span> <span class="k">return</span> <span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">];</span>

    <span class="c1">// renew the stride</span>
    <span class="kt">int</span> <span class="k">const</span> <span class="n">stride</span> <span class="o">=</span> <span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">;</span>

    <span class="c1">// in-place reduction</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">stride</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="n">stride</span><span class="p">];</span>
    <span class="p">}</span>

    <span class="c1">// call recursively</span>
    <span class="k">return</span> <span class="nf">recursiveReduce</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">stride</span><span class="p">);</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>

    <span class="c1">// initialization</span>
    <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">24</span><span class="p">;</span> <span class="c1">// total number of elements to reduce</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"%s starting reduction with array size %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">size</span><span class="p">);</span>

    <span class="c1">// execution configuration</span>
    <span class="kt">int</span> <span class="n">blocksize</span> <span class="o">=</span> <span class="mi">512</span><span class="p">;</span>   <span class="c1">// initial block size</span>

    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">blocksize</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>   <span class="c1">// block size from command line argument</span>
    <span class="p">}</span>

    <span class="c1">// allocate host memory</span>
    <span class="kt">size_t</span> <span class="n">bytes</span> <span class="o">=</span> <span class="n">size</span> <span class="o">*</span> <span class="nf">sizeof</span><span class="p">(</span><span class="kt">float</span><span class="p">);</span>
    <span class="kt">float</span> <span class="o">*</span><span class="n">h_idata</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span> <span class="o">*</span><span class="p">)</span> <span class="n">malloc</span><span class="p">(</span><span class="n">bytes</span><span class="p">);</span>

    <span class="c1">// initialize the array</span>
    <span class="k">for</span> <span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">size</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>
    <span class="p">{</span>
        <span class="n">h_idata</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="kt">float</span><span class="p">)(</span><span class="n">rand</span><span class="p">()</span> <span class="o">&amp;</span> <span class="mh">0xFF</span><span class="p">);</span>
    <span class="p">}</span>

    <span class="c1">// cpu reduction</span>
    <span class="kt">double</span> <span class="n">iStart</span> <span class="o">=</span> <span class="n">seconds</span><span class="p">();</span>
    <span class="kt">int</span> <span class="n">cpu_sum</span> <span class="o">=</span> <span class="n">recursiveReduce</span> <span class="p">(</span><span class="n">h_idata</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="kt">double</span> <span class="n">iElaps</span> <span class="o">=</span> <span class="n">seconds</span><span class="p">()</span> <span class="o">-</span> <span class="n">iStart</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"cpu reduce elapsed %f sec cpu_sum: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">iElaps</span><span class="p">,</span> <span class="n">cpu_sum</span><span class="p">);</span>

    <span class="c1">// free host memory</span>
    <span class="n">free</span><span class="p">(</span><span class="n">h_idata</span><span class="p">);</span>

    <span class="k">return</span> <span class="n">EXIT_SUCCESS</span><span class="p">;</span>
<span class="p">}</span>
</pre></table></code></div></div></blockquote><h3 id="6">6</h3><p><strong>参考核函数<code class="language-plaintext highlighter-rouge">reduceInterleaved</code>和<code class="language-plaintext highlighter-rouge">reduceCompleteUnrollWarps8</code>，实现浮点数的版本。比较它们的性能，选择合适的指标与/或事件来解释所有差异。它们相比于操作整数数据类型有什么不同吗</strong>？</p><blockquote><p>取决于架构，性能上可能有也可能没有差异。在旧的GPU架构上，争夺浮点计算单元可能会导致性能损失。但是在许多GPU上将没有性能差异，因为整型和浮点型占据同样的字节数，同一个kernel只是执行算术运算的硬件单元变了，I/O的性能不会发生变化。</p></blockquote><h3 id="7">7</h3><p><strong>动态产生的孩子对全局数据所做的修改，什么时候对父亲是可见的</strong>？</p><blockquote><p>When a parent has synchronized on the completion of its child, and continued past that synchronization.</p></blockquote><h3 id="8">8</h3><p><strong>参考文件<code class="language-plaintext highlighter-rouge">nestedHelloWorld.cu</code>， 用下图所示的方法实现一个新的核函数</strong>。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../img/professional_cuda_c_programming/chap03/child-grids-launch-2.png" alt="cuda_exe_flow" width="1086" height="542" /></p><blockquote><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
</pre><td class="rouge-code"><pre><span class="cp">#include</span> <span class="cpf">"../common/common.h"</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span>
<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">nestedHelloWorld</span><span class="p">(</span><span class="kt">int</span> <span class="k">const</span> <span class="n">iSize</span><span class="p">,</span> <span class="kt">int</span> <span class="n">minSize</span><span class="p">,</span> <span class="kt">int</span> <span class="n">iDepth</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span> <span class="o">*</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">+</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Recursion=%d: Hello World from thread %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">iDepth</span><span class="p">,</span> <span class="n">tid</span><span class="p">);</span>

    <span class="c1">// condition to stop recursive execution</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iSize</span> <span class="o">==</span> <span class="n">minSize</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>

    <span class="c1">// reduce nthreads by half</span>
    <span class="kt">int</span> <span class="n">nthreads</span> <span class="o">=</span> <span class="n">iSize</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">;</span>

    <span class="c1">// thread 0 launches child grid recursively</span>
    <span class="k">if</span><span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">nthreads</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="kt">int</span> <span class="n">blocks</span> <span class="o">=</span> <span class="p">(</span><span class="n">nthreads</span> <span class="o">+</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
        <span class="n">nestedHelloWorld</span><span class="o">&lt;&lt;&lt;</span><span class="n">blocks</span><span class="p">,</span> <span class="n">blockDim</span><span class="p">.</span><span class="n">x</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">nthreads</span><span class="p">,</span> <span class="n">minSize</span><span class="p">,</span> <span class="o">++</span><span class="n">iDepth</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"-------&gt; nested execution depth: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">iDepth</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">igrid</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">blocksize</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>

    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">igrid</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
    <span class="p">}</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">blocksize</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">]);</span>
    <span class="p">}</span>

    <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="n">igrid</span> <span class="o">*</span> <span class="n">blocksize</span><span class="p">;</span>

    <span class="n">dim3</span> <span class="nf">block</span> <span class="p">(</span><span class="n">blocksize</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="nf">grid</span>  <span class="p">((</span><span class="n">size</span> <span class="o">+</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"size = %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">size</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"igrid = %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">igrid</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"%s Execution Configuration: grid %d block %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

    <span class="n">nestedHelloWorld</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">size</span><span class="p">,</span> <span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">);</span>

    <span class="n">CHECK</span><span class="p">(</span><span class="n">cudaGetLastError</span><span class="p">());</span>
    <span class="n">CHECK</span><span class="p">(</span><span class="n">cudaDeviceSynchronize</span><span class="p">());</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></table></code></div></div></blockquote><h3 id="9">9</h3><p><strong>参考文件<code class="language-plaintext highlighter-rouge">nestedHelloWorld.cu</code>，实现一个新的核函数， 使其可以用给定深度来限制嵌套层</strong>。</p><blockquote><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
</pre><td class="rouge-code"><pre><span class="cp">#include</span> <span class="cpf">"../common/common.h"</span><span class="cp">
#include</span> <span class="cpf">&lt;stdio.h&gt;</span><span class="cp">
#include</span> <span class="cpf">&lt;cuda_runtime.h&gt;</span><span class="cp">
</span>
<span class="cm">/*
 * A simple example of nested kernel launches from the GPU. Each thread displays
 * its information when execution begins, and also diagnostics when the next
 * lowest nesting layer completes.
 */</span>

<span class="n">__global__</span> <span class="kt">void</span> <span class="nf">nestedHelloWorld</span><span class="p">(</span><span class="kt">int</span> <span class="k">const</span> <span class="n">iSize</span><span class="p">,</span> <span class="kt">int</span> <span class="n">iDepth</span><span class="p">,</span> <span class="kt">int</span> <span class="n">maxDepth</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">tid</span> <span class="o">=</span> <span class="n">threadIdx</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"Recursion=%d: Hello World from thread %d block %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">iDepth</span><span class="p">,</span> <span class="n">tid</span><span class="p">,</span> <span class="n">blockIdx</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

    <span class="c1">// condition to stop recursive execution</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">iSize</span> <span class="o">==</span> <span class="mi">1</span> <span class="o">||</span> <span class="n">iDepth</span> <span class="o">&gt;=</span> <span class="n">maxDepth</span><span class="p">)</span> <span class="k">return</span><span class="p">;</span>

    <span class="c1">// reduce block size to half</span>
    <span class="kt">int</span> <span class="n">nthreads</span> <span class="o">=</span> <span class="n">iSize</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">;</span>

    <span class="c1">// thread 0 launches child grid recursively</span>
    <span class="k">if</span><span class="p">(</span><span class="n">tid</span> <span class="o">==</span> <span class="mi">0</span> <span class="o">&amp;&amp;</span> <span class="n">nthreads</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">nestedHelloWorld</span><span class="o">&lt;&lt;&lt;</span><span class="mi">1</span><span class="p">,</span> <span class="n">nthreads</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">nthreads</span><span class="p">,</span> <span class="o">++</span><span class="n">iDepth</span><span class="p">,</span> <span class="n">maxDepth</span><span class="p">);</span>
        <span class="n">printf</span><span class="p">(</span><span class="s">"-------&gt; nested execution depth: %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">iDepth</span><span class="p">);</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="kt">int</span> <span class="nf">main</span><span class="p">(</span><span class="kt">int</span> <span class="n">argc</span><span class="p">,</span> <span class="kt">char</span> <span class="o">**</span><span class="n">argv</span><span class="p">)</span>
<span class="p">{</span>
    <span class="kt">int</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>
    <span class="kt">int</span> <span class="n">blocksize</span> <span class="o">=</span> <span class="mi">8</span><span class="p">;</span>   <span class="c1">// initial block size</span>
    <span class="kt">int</span> <span class="n">igrid</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>

    <span class="k">if</span><span class="p">(</span><span class="n">argc</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span> <span class="p">{</span>
        <span class="n">igrid</span> <span class="o">=</span> <span class="n">atoi</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>
        <span class="n">size</span> <span class="o">=</span> <span class="n">igrid</span> <span class="o">*</span> <span class="n">blocksize</span><span class="p">;</span>
    <span class="p">}</span>

    <span class="n">dim3</span> <span class="nf">block</span> <span class="p">(</span><span class="n">blocksize</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">dim3</span> <span class="nf">grid</span>  <span class="p">((</span><span class="n">size</span> <span class="o">+</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">);</span>
    <span class="n">printf</span><span class="p">(</span><span class="s">"%s Execution Configuration: grid %d block %d</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">argv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grid</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">);</span>

    <span class="n">nestedHelloWorld</span><span class="o">&lt;&lt;&lt;</span><span class="n">grid</span><span class="p">,</span> <span class="n">block</span><span class="o">&gt;&gt;&gt;</span><span class="p">(</span><span class="n">block</span><span class="p">.</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">);</span>

    <span class="n">CHECK</span><span class="p">(</span><span class="n">cudaGetLastError</span><span class="p">());</span>
    <span class="n">CHECK</span><span class="p">(</span><span class="n">cudaDeviceReset</span><span class="p">());</span>
    <span class="k">return</span> <span class="mi">0</span><span class="p">;</span>
<span class="p">}</span>
</pre></table></code></div></div></blockquote></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/cuda/'>CUDA</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/gpu/" class="post-tag no-text-decoration" >GPU</a> <a href="/tags/cuda/" class="post-tag no-text-decoration" >CUDA</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=读薄《Professional CUDA C Programming》——CUDA执行模型 - zuo&url=https://dazuozcy.github.io/posts/cuda-c-chap03/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=读薄《Professional CUDA C Programming》——CUDA执行模型 - zuo&u=https://dazuozcy.github.io/posts/cuda-c-chap03/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=读薄《Professional CUDA C Programming》——CUDA执行模型 - zuo&url=https://dazuozcy.github.io/posts/cuda-c-chap03/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/simd/">SIMD</a><li><a href="/posts/new-from-cpp11/">C++11开始的新特性</a><li><a href="/posts/keywords/">关键字</a><li><a href="/posts/empty-class/">class的内存模型</a><li><a href="/posts/diff-between-c-cpp/">C++ vs C</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/gpu/">GPU</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/openmp/">openMP</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/parallel-computing/">Parallel Computing</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/forecasting-at-scale/">Forecasting at Scale</a> <a class="post-tag" href="/tags/onednn/">oneDNN</a> <a class="post-tag" href="/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/">智能指针</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/cuda-c-chap01/"><div class="card-body"> <span class="timeago small" > Jul 1, 2020 <i class="unloaded">2020-07-01T20:19:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>读薄《Professional CUDA C Programming》——基于CUDA的异构并行编程</h3><div class="text-muted small"><p> 一、基于CUDA的异构并行编程 并行计算 并行计算的主要目标是提高计算速度。并行计算的软件和硬件层面是紧密联系的，传说中的软硬件协同。并行计算通常涉及两个不同的计算技术领域： 计算机架构（硬件方面），关注的是在结构层次上支持并行性。 并行程序设计（软件方面），关注的是充分使用架构的计算能力来并发地解决问题。 并行性 在并行算法的实现中， 分析数据的相关性是最基本的内容，...</p></div></div></a></div><div class="card"> <a href="/posts/cuda-c-chap02/"><div class="card-body"> <span class="timeago small" > Jul 1, 2020 <i class="unloaded">2020-07-01T20:19:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>读薄《Professional CUDA C Programming》——CUDA编程模型</h3><div class="text-muted small"><p> 二、CUDA编程模型 CUDA编程模型概述 CUDA编程结构 站在程序员的角度，可以从以下几个不同层面来看待并行计算： 领域层(Domain level) 逻辑层(Logic level) 硬件层(Hardware level) 这三个层面对应了并行计算编程的不同阶段： 算法设计阶段，最关心的应是在领域层如何解析数据和函数，以便在并行环境中能正确、高效地解决...</p></div></div></a></div><div class="card"> <a href="/posts/cuda-c-chap04/"><div class="card-body"> <span class="timeago small" > Jul 1, 2020 <i class="unloaded">2020-07-01T20:19:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>读薄《Professional CUDA C Programming》——全局内存</h3><div class="text-muted small"><p> 四、全局内存 本章将剖析核函数与全局内存的联系及其对性能的影响。本章将介绍CUDA内存模型， 并通过分析不同的全局内存访问模式来介绍如何通过核函数高效地利用全局内存。 CUDA内存模型概述 在现有的硬件存储子系统下，必须依靠内存模型获得最佳的延迟和带宽。CUDA内存模型结合了主机和设备的内存系统，展现了完整的内存层次结构，使你能显式地控制数据布局以优化性能。 内存层次结构的优点 一...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/cuda-c-chap02/" class="btn btn-outline-primary" prompt="Older"><p>读薄《Professional CUDA C Programming》——CUDA编程模型</p></a> <a href="/posts/cuda-c-chap04/" class="btn btn-outline-primary" prompt="Newer"><p>读薄《Professional CUDA C Programming》——全局内存</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/dazuozcy">zuo</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/gpu/">GPU</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/openmp/">openMP</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/parallel-computing/">Parallel Computing</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/forecasting-at-scale/">Forecasting at Scale</a> <a class="post-tag" href="/tags/onednn/">oneDNN</a> <a class="post-tag" href="/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/">智能指针</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://dazuozcy.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script>
