<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting" /><meta name="author" content="dazuo" /><meta property="og:locale" content="en_US" /><meta name="description" content="Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting" /><meta property="og:description" content="Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting" /><link rel="canonical" href="https://dazuozcy.github.io/posts/ASTGCN/" /><meta property="og:url" content="https://dazuozcy.github.io/posts/ASTGCN/" /><meta property="og:site_name" content="zuo" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-07-02T20:19:00+08:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"dazuo"},"dateModified":"2022-08-29T11:23:36+08:00","datePublished":"2020-07-02T20:19:00+08:00","description":"Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting","headline":"ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting","mainEntityOfPage":{"@type":"WebPage","@id":"https://dazuozcy.github.io/posts/ASTGCN/"},"url":"https://dazuozcy.github.io/posts/ASTGCN/"}</script><title>ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting | zuo</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="zuo"><meta name="application-name" content="zuo"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"><link rel="preload" href="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js" as="script"> <script async src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="https://cdn.jsdelivr.net/gh/cotes2020/chirpy-images/commons/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">zuo</a></div><div class="site-subtitle font-italic">感谢永远有歌把心境道破</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream ml-xl-3 mr-xl-3 unloaded"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>ABOUT</span> </a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/dazuozcy" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['dazuozcy','163.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> dazuo </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Thu, Jul 2, 2020, 8:19 PM +0800" prep="on" > Jul 2, 2020 <i class="unloaded">2020-07-02T20:19:00+08:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Mon, Aug 29, 2022, 11:23 AM +0800" prefix="Updated " > Aug 29, 2022 <i class="unloaded">2022-08-29T11:23:36+08:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="8319 words">46 min</span></div></div><div class="post-content"><blockquote><p><a href="https://ojs.aaai.org/index.php/AAAI/article/view/3881">Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting</a></p></blockquote><h1 id="摘要">摘要</h1><p><strong>交通流预测</strong>是交通领域研究者和实践者面临的一个关键问题。然而由于交通流的<strong>高度非线性</strong>和<strong>复杂的模式</strong>，交通流问题非常具有挑战性。</p><p>现有的大多数交通流预测方法缺乏对交通数据的<strong>动态时空相关性</strong>的建模能力，因此无法产生令人满意的预测结果。</p><p>本文提出了一种新的<strong>基于注意力机制的时空图卷积网络模型</strong>(<code class="language-plaintext highlighter-rouge">ASTGCN</code>)来解决交通流预测问题。</p><p><code class="language-plaintext highlighter-rouge">ASTGCN</code>主要由三个独立部分组成，分别模拟交通流的<strong>三个时间特性</strong>：最近、每日和每周的依赖。</p><p>更具体地说，每个组件包含两个主要部分：</p><ul><li><strong>时空注意力机制</strong>，用于有效捕获交通数据中的<strong>动态时空相关性</strong>；<li><strong>时空卷积</strong>，<strong>图卷积</strong>来捕获<strong>空间模式</strong>和常用<strong>标准卷积</strong>来描述<strong>时间特征</strong>。</ul><p>对三个分量的输出<strong>加权融合</strong>成最终的预测结果。</p><p>在<code class="language-plaintext highlighter-rouge">Caltrans</code>性能测量系统的两个真实数据集上的实验表明，所提出的<code class="language-plaintext highlighter-rouge">ASTGCN</code>模型优于最先进的基线。</p><h1 id="引言">引言</h1><p>近年来，许多国家都致力于大力发展智能交通系统(<code class="language-plaintext highlighter-rouge">ITS</code>)以实现高效的交通管理。交通预测是<code class="language-plaintext highlighter-rouge">ITS</code>不可或缺的一部分，尤其是在流量大、速度快的高速公路上。由于高速相对封闭，一旦发生拥堵，将严重影响通行能力。<strong>交通流</strong>是反映高速状态的基本测量指标。如果能够提前准确预测，交管部门将能够更合理地引导车辆，提高高速网的运行效率。</p><p>公路交通流预测是一个典型的<strong>时空数据预测问题</strong>。交通数据在固定时间和连续空间中的固定位置上被记录。显然，在相邻位置和时间点进行的观测不是独立的，而是动态关联的。因此，解决这些问题的关键是有效地提取数据的时空相关性。</p><p>图<code class="language-plaintext highlighter-rouge">1</code>展示了交通流的时空相关性(可以是车速、车道占用率等)。两点之间的粗线表示其相互影响的强度。线的颜色越深，影响越大。在空间维度.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../../../img/gnn/astgcn_paper/spatial-temporal_correlation.png" alt="" width="1086" height="542" /><em>图1: 交通流的时空相关性图表</em></p><p>图<code class="language-plaintext highlighter-rouge">1(a)</code>中，可以发现不同位置对<code class="language-plaintext highlighter-rouge">A</code>的影响不同，甚至同一位置对<code class="language-plaintext highlighter-rouge">A</code>的影响也随着时间的推移而不同。</p><p>图<code class="language-plaintext highlighter-rouge">1(b)</code>中，在时间维度里不同位置的历史观测对<code class="language-plaintext highlighter-rouge">A</code>未来不同时间的交通状态有不同的影响。</p><p>总之，高速网交通数据中的相关性在空间维度和时间维度上都表现出强烈的动态性。如何探索非线性和复杂的时空数据，以发现其内在的时空模式，并作出准确的交通流预测是一个非常具有挑战性的问题。</p><p>幸运的是，随着运输业的发展，许多摄像机、传感器和其他信息采集设备已经部署在高速公路上。每个设备都放置在特定的空间位置，不断产生交通的时间序列数据。这些设备积累了大量丰富的带地理信息的交通时间序列数据，为交通预测提供了坚实的数据基础。许多研究者已经做出了很多努力来解决这些问题。</p><p>早期，时间序列分析模型用于交通预测问题。然而，在实际应用中，他们很难处理不稳定和非线性的数据。</p><p>后来，传统机器学习方法用来建模更复杂的数据，但它们仍然难以同时考虑高维交通数据的时空相关性。此外，这种方法的预测效果很大程度上依赖于特征工程，这通常需要相应领域专家的大量经验。</p><p>近年来，许多研究人员使用深度学习方法来处理高维时空数据，例如，卷积神经网络被用来有效地提取网格化数据的空间特征；图卷积神经网络用于描述图结构数据的空间相关性。然而，这些方法仍然无法同时建模交通数据的时空特征和动态相关性。</p><p>为了应对上述挑战，我们提出了一种新的深度学习模型：基于注意力机制的时空图卷积网络<code class="language-plaintext highlighter-rouge">ASTGCN</code>，用于集中预测交通网络上每个位置的交通流。该模型可以直接在原始的基于图的交通网络上处理交通数据，有效地捕捉动态时空特征。</p><h2 id="主要贡献">主要贡献</h2><ul><li>提出了一种<strong>时空注意力机制</strong>来学习交通数据的动态时空相关性。<ul><li><strong>空间注意力机制</strong>用于捕捉不同<strong>位置</strong>之间的<strong>动态空间相关性</strong>。<li><strong>时间注意力机制</strong>用于捕捉不同<strong>时间</strong>之间的<strong>动态时间相关性</strong>。</ul><li>设计了一种<strong>时空卷积模块</strong>，用于建模交通数据的<strong>时空相关性</strong>。它包括<ul><li><strong>图卷积</strong>用于从原始的基于图的交通网络结构中捕获<strong>空间特征</strong>。<li><strong>时间维度卷积</strong>用于描述临近时间片的依赖关系。</ul><li>基于真实公路交通数据集进行了大量实验，验证了与现有基线相比，我们的模型实现了最佳预测效果。</ul><h1 id="相关工作">相关工作</h1><h2 id="交通预测">交通预测</h2><p>经过多年的不断研究和实践，交通预测的研究取得了许多成果。</p><ul><li><p>统计模型</p><p>用于交通预测的统计模型包括<code class="language-plaintext highlighter-rouge">HA</code>、<code class="language-plaintext highlighter-rouge">ARIMA</code>、<code class="language-plaintext highlighter-rouge">VAR</code>等。这些方法要求数据满足某些假设，但交通数据太复杂，无法满足这些假设，因此在实践中通常表现不佳。</p><li><p>传统机器学习模型</p><p>机器学习方法，如<code class="language-plaintext highlighter-rouge">KNN</code>和<code class="language-plaintext highlighter-rouge">SVM</code>可以建模更复杂的数据，但它们需要仔细的特征工程。</p><li><p>深度学习模型</p><p>由于深度学习在语音识别和图像处理等许多领域取得了突破，越来越多的研究人员将深度学习应用于时空数据预测。张等人设计了一个基于残差卷积单元的<code class="language-plaintext highlighter-rouge">ST-ResNet</code>模型来预测人群流量。姚等人提出了一种通过整合<code class="language-plaintext highlighter-rouge">CNN和</code>长短时记忆<code class="language-plaintext highlighter-rouge">LSTM</code>来联合建模空间和时间依赖性来预测流量的方法。姚等人进一步提出了一种用于出租车需求预测的时空动态网络，该网络可以动态学习位置之间的相似性。虽然这些模型可以提取交通数据的时空特征，但其局限性在于输入必须是标准的二维或三维网格数据。</p></ul><h2 id="图数据上的卷积">图数据上的卷积</h2><p>传统卷积可以有效地提取数据的局部特征，但它只能应用于标准网格数据。最近，图卷积将传统卷积推广到图结构的数据。图卷积方法的两个主流是空间方法和谱方法。</p><p>空间方法直接对图的节点及其邻居执行卷积滤波。因此，这种方法的核心是选择节点的邻域。<code class="language-plaintext highlighter-rouge">Niepert</code>、<code class="language-plaintext highlighter-rouge">Ahmed</code>和<code class="language-plaintext highlighter-rouge">Kutzkov</code>提出了一种启发式线性方法来选择每个中心节点的邻域，在社交网络任务中取得了良好的效果。李等人将图卷积引入到人类行为识别任务中。本文提出了几种划分策略，将每个节点的邻域划分为不同的子集，并确保每个节点的子集数量相等。</p><p>谱方法，其中通过谱分析考虑图卷积的局部性。<code class="language-plaintext highlighter-rouge">Bruna</code>等人提出了一种基于<strong>图拉普拉斯</strong>的通用图卷积框架，然后<code class="language-plaintext highlighter-rouge">Defferard</code>、<code class="language-plaintext highlighter-rouge">Bresson</code>和<code class="language-plaintext highlighter-rouge">Vandergheynst</code>通过使用<strong>切比雪夫多项式</strong>近似实现特征值分解来优化该方法。<code class="language-plaintext highlighter-rouge">Yu</code>、<code class="language-plaintext highlighter-rouge">Yin</code>和<code class="language-plaintext highlighter-rouge">Zhu</code>提出了一种基于该方法的交通预测门控图卷积网络，但该模型没有考虑交通数据的动态时空相关性。</p><h2 id="注意力机制">注意力机制</h2><p>近年来，注意力机制已广泛应用于各种任务，如自然语言处理、图像字幕和语音识别。<strong>注意力机制的目标是从所有输入中选择对当前任务相对关键的信息</strong>。徐等人在图像描述任务中提出了两种注意机制，并采用可视化方法直观地展示了注意机制的效果。为了对图的节点进行分类，<code class="language-plaintext highlighter-rouge">Velickovic</code>等人通过神经网络利用自注意力层来处理图结构数据，并取得了最先进的效果。为了预测时间序列，梁等人提出了一种多级注意力网络，以自适应调整多个地理位置的传感器的时间序列之间的相关性。然而，由于需要为每个时间序列训练单独的模型，因此在实践中非常耗时。</p><p>基于上述研究，考虑交通网络的图结构和交通数据的动态时空模式，我们同时采用图卷积和注意力机制对网络结构的交通数据进行建模。</p><h1 id="基本定义和引理">基本定义和引理</h1><h2 id="交通网络">交通网络</h2><p>本研究中，我们将交通网络定义为无向图 $G=(V,E,\mathbf{A})$，如图<code class="language-plaintext highlighter-rouge">2(a)</code>所示，其中 $V$ 是 $\vert V \vert =N$ 个节点的有限集；$E$ 是一组边，表示节点之间的连接；$\mathbf{A} \in \mathbb{R}^{N\times N}$表示图 $G$ 的邻接矩阵。交通网络 $G$ 上的每个节点以相同采样频率检测出 $F$ 个测量值（如速度、流量、时间占有率等），即每个节点在每个时间片上生成长度为 $F$ 的特征向量，如图<code class="language-plaintext highlighter-rouge">2(b)</code>中的实线所示。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../../../img/gnn/astgcn_paper/traffic_network.png" alt="" width="1086" height="542" /> <em>图2: <code class="language-plaintext highlighter-rouge">(a)</code> 交通数据的时空结构，每个时间段的数据形成一个图; <code class="language-plaintext highlighter-rouge">(b)</code> 一个节点上检测到三个测量值，预测目标未来交通流。这里所有测量值均归一化为$[0,1]$。</em></p><h2 id="交通流预测">交通流预测</h2><p>假设交通网络 $G$ 中每个节点上记录的第 $f$ 个时间序列是交通流序列，并且$f \in (1,…,F)$。</p><p>我们使用 $x_{t}^{c,i} \in \mathbb{R}$ 表示节点 $i$ 在时间 $t$ 的第 $c$ 个特征值，$\mathbf{x}_{t}^{i} \in \mathbb{R}^{F}$ 表示节点 $i$ 在时间 $t$ 的所有特征值。</p><p>\(X_{t}=(\mathbf{x}_{t}^{1},\mathbf{x}_{t}^{2},...,\mathbf{x}_{t}^{N})^{T} \in \mathbb{R}^{N \times F}\)表示 $t$ 时刻的所有节点的所有特征值。</p><p>\(\mathbf{X}=(\mathbf{X}_{1},\mathbf{X}_{2},...,\mathbf{X}_{\tau})^{T} \in \mathbb{R} ^{N \times F \times \tau}\) 表示 $\tau$ 时间切片上所有节点的所有特征值。</p><p>此外，我们设置 $y_{t}^{i}=x_{t}^{f,i} \in \mathbb{R}$ 表示节点 $i$ 在未来时间 $t$ 的交通流。</p><h3 id="问题">问题</h3><p>给定过去 $\tau$ 个时间片内交通网络上所有节点的历史测量值 $\pmb{X}$ ，预测未来 $T_{p}$ 个时间片整个交通网络所有节点的未来交通流序列 $\pmb{Y}=(\pmb{y}^{1},\pmb{y}^{2},…,\pmb{y}^{N})^{T} \in \mathbb{R}^{N×T_{p}}$，其中 $\pmb{y}^{i}=(y_{τ+1}^{i},y_{τ+2}^{i},…,y_{τ+T_{p}}^{i}) \in \mathbb{R}^{T_{p}}$ 表示从 $τ+1$ 时刻开始，节点 $i$ 的未来交通流。</p><h1 id="astgcn">ASTGCN</h1><p>图3为本文提出的<code class="language-plaintext highlighter-rouge">ASTGCN</code>模型的总体框架。由三个相同结构的独立部分组成，分别用于建模历史数据的<strong>最近</strong>、<strong>日周期</strong>和<strong>周周期</strong>依赖关系。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../../../img/gnn/astgcn_paper/astgcn_framwork.png" alt="image-20220729163818826" width="1086" height="542" /><em>图3: <code class="language-plaintext highlighter-rouge">ASTGCN</code>的框架。<code class="language-plaintext highlighter-rouge">SAtt</code>:空间注意力;<code class="language-plaintext highlighter-rouge">TAtt</code>:: 时间注意力; <code class="language-plaintext highlighter-rouge">GCN</code>: 图卷积; <code class="language-plaintext highlighter-rouge">FC</code>: 全连接; <code class="language-plaintext highlighter-rouge">ST block</code>：时空块。</em></p><p>假设采样频率为每天 $q$ 次。假设当前时间为 $t_{0}$，预测窗口的大小为 $T_{p}$.</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../../../img/gnn/astgcn_paper/time_series_segments.png" alt="image-20220729165621897" width="1086" height="542" /><em>图4: 构建时间序列段输入的示例（假设预测窗口大小为1小时，$T_{h}$、$T_{d}$ 和 $T_{w}$ 是 $T_{p}$ 的两倍)</em></p><p>如图4所示，我们沿时间轴截取长度为 $T_{h}$、$T_{d}$和 $T_{w}$的三个时间序列段，分别作为最近、每日和每周周期分量的输入，其中 $T_{h}$、$T_{d}$和 $T_{w}$都是 $T_{p}$的整数倍。关于三个时间序列段的详细信息如下：</p><ul><li><p><code class="language-plaintext highlighter-rouge">recent</code>-段</p>\[\mathbf{X}_{h}=(\mathbf{X}_{t_{0}−T_{h}+1},\mathbf{X}_{t_{0}−T_{h}+2},...,\mathbf{X}_{t_{0}}) \in \mathbb{R}^{N \times F \times T_{h}}\]<p>一段与预测时间序列直接相邻的历史时间序列，如图4的绿色部分所示。直观上，交通拥堵的形成和扩散是渐进的。因此，刚过去的交通流必然会对未来的交通流产生影响。</p><li><p>日-周期段</p>\[\mathbf{X}_{d}=(\mathbf{X}_{t_{0}−(T_{d}/T_{p})*q+1},...,\mathbf{X}_{t_{0}−(T_{d}/T_{p})*q+T_{p}}, \mathbf{X}_{t_{0}−(T_{d}/T_{p}-1)*q+1},...,\mathbf{X}_{t_{0}−(T_{d}/T_{p}-1)*q+T_{p}},...,\mathbf{X}_{t_{0}-q+1},...,\mathbf{X}_{t_{0}-q+T_{p}}) \in \mathbb{R}^{N \times F \times T_{d}}\]<p>由过去几天与预测期处于同一时间段的路段组成，如图4的红色部分所示。由于人们的日常生活规律，交通数据可能会显示重复模式，例如每天早上的高峰。日周期分量的目的是对交通数据的日周期性进行建模。</p><li><p>周-周期段</p>\[\mathbf{X}_{w}=(\mathbf{X}_{t_{0}−7*(T_{d}/T_{p})*q+1},...,\mathbf{X}_{t_{0}−7*(T_{d}/T_{p})*q+T_{p}}, \mathbf{X}_{t_{0}−7*(T_{d}/T_{p}-1)*q+1},...,\mathbf{X}_{t_{0}−7*(T_{d}/T_{p}-1)*q+T_{p}},...,\mathbf{X}_{t_{0}-7*q+1},...,\mathbf{X}_{t_{0}-7*q+T_{p}}) \in \mathbb{R}^{N \times F \times T_{w}}\]<p>由过去几周的路段组成，这些路段具有与预测期相同的周属性和时间间隔，如图4的蓝色部分所示。通常，周一的交通模式与历史上的周一交通模式有一定的相似性，但可能与周末的交通模式有很大的不同。因此，周周期分量旨在捕捉交通数据中的周周期特征。</p></ul><p>这三个部分有相同的网络结构，每部分由多个时空块和一个全连接层组成。在每个时空块中都有一个时空注意力模块和一个时空卷积模块。为了优化训练效率，每个组件中采用了<strong>残差连接</strong><code class="language-plaintext highlighter-rouge">residual learning framework</code>。最后，基于参数矩阵进一步合并三个分量的输出，以获得最终的预测结果。整体网络结构经过精心设计以描述交通流的动态时空相关性。</p><h2 id="时空注意力">时空注意力</h2><p>在我们的模型中提出了一种新的时空注意力机制，用于捕捉交通网络上的动态时空相关性(如图1所示)。它包含空间注意力和时间注意力。</p><h3 id="空间注意力">空间注意力</h3><p>在空间维度上，不同地点的交通条件相互影响，且影响是高度动态的。这里我们使用注意力机制来自适应地捕捉空间维度中节点间的动态相关性。以最近组件中的空间注意力为例：</p>\[\mathbf{S} = \mathbf{V}_{s} \cdot \sigma \Big( \big( \mathbf{X}_{h}^{(r-1)} \mathbf{W}_{1} \big) \mathbf{W}_{2} \big(\mathbf{W}_{3}\mathbf{X}_{h}^{(r-1)} \big)^{T} + \mathbf{b}_{s} \Big)\] \[\mathbf{S}_{i,j}^{\mathbf{'}} = \frac { \text{exp}(\mathbf{S}_{i,j}) } { \sum_{j=1}^{N}\text{exp}(\mathbf{s}_{i,j}) }\]<p>其中，\(\mathbf{X}_{h}^{(r-1)}=(\mathbf{X}_{1},\mathbf{X}_{2},...,\mathbf{X}_{T_{r-1}}) \in \mathbb{R}^{N \times C_{r-1} \times T_{r-1}}\) 是第 \(r\) 个时空块的输入。</p><p>$C_{r-1}$ 是第 $r$ 层中输入数据的通道数。$T_{r-1}$ 是第 $r$ 层中时间维度的长度。</p><p>当 $r=1$ 时，$C_{0}=F$ ，$T_{0}=T_{h}$ (recent分量)、$T_{0}=T_{d}$ (日周期分量)、$T_{0}=T_{w}$ (周周期分量)</p><p>\(\mathbf{V}_{s}\), \(\mathbf{b}_{s} \in \mathbb{R}^{N \times N}\)，\(\mathbf{W}_{1} \in \mathbb{R}^{T_{r-1}}\)，\(\mathbf{W}_{2} \in \mathbb{R}^{C_{r-1} \times T_{r-1}}\)，\(\pmb{W}_{3} \in \mathbb{R}^{C_{r-1}}\) 是可学习的参数，<code class="language-plaintext highlighter-rouge">sigmoid</code> $\sigma$ 用作激活函数。</p><p>注意力矩阵 $\mathbf{S}$ 根据该层的当前输入动态计算。$\mathbf{S}$ 中元素 $\mathbf{S}_{i,j}$ 的值在语义上表示节点 $i$ 和节点 $j$ 间的相关性强度。然后使用<code class="language-plaintext highlighter-rouge">softmax</code>函数确保节点的注意力权重总和为1。在执行图卷积时，我们将联合邻接矩阵 $\mathbf{A}$ 和空间注意矩阵 \(\mathbf{S^{'}} \in \mathbb{R}^{N \times N}\) 动态调整节点之间的权重。</p><h3 id="时间注意力">时间注意力</h3><p>在时间维度上，不同时间段的交通状况间存在相关性，且不同情况下相关性也不同。我们使用注意力机制自适应地赋予数据不同的重要性:</p>\[\pmb{E}=\pmb{V}_{e} \cdot \sigma(((\pmb{X}_{h}^{(r-1)})^{T}\pmb{U}_{1})\pmb{U}_{2}(\pmb{U}_{3}\pmb{X}_{h}^{(r-1)})^{T} + \pmb{b}_{e})\] \[\pmb{E}_{i,j}^{\pmb{'}}=\frac{exp(\pmb{E}_{i,j})}{\sum_{j=1}^{T_{r-1}}exp(\pmb{E}_{i,j})}\]<p>其中，\(\mathbf{V}_{e}\), \(\mathbf{b}_{e} \in \mathbb{R}^{T_{r-1} \times T_{r-1}}\)，\(\mathbf{U}_{1} \in \mathbb{R}^{N}\)，\(\mathbf{U}_{2} \in \mathbb{R}^{C_{r-1} \times N}\)，\(\mathbf{U}_{3} \in \mathbb{R}^{C_{r-1}}\) 是可学习参数。</p><p>时间相关矩阵 $E$ 由变化的输入决定。$E$ 中元素 $E_{i,j}$ 的值在语义上表示时间 $i$ 和 $j$ 之间的依赖强度。最后 $E$ 通过<code class="language-plaintext highlighter-rouge">softmax</code>函数归一化。我们直接将归一化的时间注意力矩阵作用于输入，得到 \(\mathbf{\hat{\mathbf{X}}}_{h}^{r-1}=(\mathbf{\hat{\mathbf{X}}}_{1},\mathbf{\hat{\mathbf{X}}}_{2},...,\mathbf{\hat{\mathbf{X}}}_{T_{r-1}})=(\mathbf{X}_{1},\mathbf{X}_{2},...,\mathbf{X}_{T_{r-1}})\mathbf{E^{'}} \in \mathbb{R}^{N \times C_{r-1} \times T_{r-1}}\)，通过融合相关信息实现动态调整输入。</p><h2 id="时空卷积">时空卷积</h2><p>时空注意力模块让网络自动对有价值的信息给予相对更多的关注。注意力机制调整过的输入被送入时空卷积模块，其结构如图5所示。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../../../img/gnn/astgcn_paper/spatial_temporal_conv.png" alt="image-20220730162034184" width="1086" height="542" /><em>图5: ASTGCN中时空卷积模块的结构</em></p><p>本文提出的时空卷积模块包括空间维度的图卷积，其从邻域捕获空间依赖性；以及沿时间维度的卷积，其探索邻近时间的时间依赖性。</p><h3 id="空间维度的图卷积">空间维度的图卷积</h3><p>图谱论将卷积运算从基于网格的数据推广到图结构数据。本研究中，交通网络本质上是一个图结构，每个节点的特征可视为图上的信号。因此，为了充分利用交通网络的拓扑特性，在每个时间切片上，我们采用基于图谱论的图卷积来直接处理信号，利用交通网络在空间维度上的信号相关性。谱方法将图转换为代数形式，以分析图的拓扑属性，例如图结构中的连通性。</p><p>在谱分析中，图由其相应的拉普拉斯矩阵表示。通过分析拉普拉斯矩阵及其特征值，可以得到图的结构的性质。图的拉普拉斯矩阵定义为$\mathbf{L}=\mathbf{D}−\mathbf{A}$、 其归一化形式为 \(\mathbf{L}=\mathbf{I}_{N} - \mathbf{D}^{-\frac{1}{2}} \mathbf{A} \mathbf{D}^{\frac{1}{2}} \in \mathbb{R}^{N \times N}\) ，其中 \(\mathbf{A}\) 是邻接矩阵，\(\mathbf{I}_{N}\) 是单位矩阵，度矩阵 \(\mathbf{D} \in \mathbb{R}^{N \times N}\) 是一个对角矩阵，由节点的度 \(\mathbf{D}_{ii}=\sum_{j} \mathbf{A}_{ij}\) 组成。拉普拉斯矩阵的特征值分解为 \(\mathbf{L}=\mathbf{U} \mathbf{\Lambda} \mathbf{U}^{T}\)，其中 \(\mathbf{\Lambda}=diag([\lambda_{0},...,\lambda_{N-1}]) \in \mathbb{R}^{N \times N}\) 是对角矩阵，\(\mathbf{U}\) 是傅立叶基。</p><p>以 $t$ 时刻的交通流为例，图上的信号为 \(x=\mathbf{x}_{t}^{f} \in \mathbb{R}^{N}\)，信号的图傅立叶变换定义为 \(\hat{x}=\mathbf{U}^{T} x\)。根据拉普拉斯矩阵的性质，\(\mathbf{U}\) 是正交矩阵，因此相应的傅立叶逆变换为 \(x=\mathbf{U} \hat{x}\) 式。图卷积是一种卷积运算，通过使用在傅立叶域中对角化的线性算子来代替经典卷积算子来实现。基于此，图 $G$ 上的信号 \(x\) 由核 \(g_{\theta}\) 滤波：</p>\[g_{\theta} \ \ast_{G} x = g_{\theta}(\mathbf{L})x = g_{\theta} (\mathbf{U} \mathbf{\Lambda} \mathbf{U}^{T}) x = \mathbf{U}g_{\theta}(\mathbf{\Lambda}) \mathbf{U}^{T} x\]<p>其中，\(\ast_{G}\) 表示图卷积运算。由于图信号的卷积运算等价于通过图傅立叶变换转换到频谱域的信号的乘积，因此上述公式可以理解为分别将 \(g_{\theta}\) 和 \(x\) 做傅立叶变换到频谱域，然后将转换后的结果相乘，再做傅里叶逆变换，得到卷积的最终结果。然而，当图的规模较大时，直接在拉普拉斯矩阵上做特征值分解是费时的。因此，本文采用切比雪夫多项式近似但有效地解决这个问题：</p>\[g_{\theta} \ \ast_{G} x = g_{\theta}(\mathbf{L})x = \sum_{k=0}^{K-1}\theta_{k}T_{k}(\mathbf{\tilde{L}}) x\]<p>其中，\(\theta \in \mathbb{R}^{K}\) 是多项式系数的向量。\(\mathbf{\tilde{L}}=\frac{2}{\lambda_{max}} \mathbf{L} - \mathbf{I_{N}}\)，\(\lambda_{max}\) 是拉普拉斯矩阵特征值的最大值。</p><p>切比雪夫多项式的递归定义是： \(T_{k}(x)=2xT_{k-1}(x)-T_{k-2}(x)\)，其中，\(T_{0}(x)=1\)，\(T_{1}(x)=x\)。</p><p>使用切比雪夫多项式的近似展开来求解该公式对应于通过卷积核 \(g_{\theta}\) 提取图上每个节点周围 $0$ 到 \(K-1\) 阶邻域的信息。</p><p>图卷积模块使用<code class="language-plaintext highlighter-rouge">ReLU</code>作为最终的激活函数，即 \(ReLU(g_{\theta} \ast_{G} x)\)。</p><p>为了动态调整节点间的相关性，对于切比雪夫多项式的每一项，我们将 \(T_{k}(\mathbf{\tilde{L}})\) 与空间注意矩阵 \(\mathbf{S}^{'} \in \mathbb{R}^{N \times N}\) 结合起来，然后获得 \(T_{k}(\mathbf{\tilde{L}}) \odot \mathbf{S}^{'}\)，其中 \(\odot\) 是<code class="language-plaintext highlighter-rouge">Hadamard</code>乘积。因此，上述图卷积公式变为</p><p>\(g_{\theta} \ \ast_{G} x = g_{\theta}(\mathbf{L})x = \sum_{k=0}^{K-1}\theta_{k} (T_{k}(\mathbf{\tilde{L}}) \odot \mathbf{S^{'}}) x\).</p><p>我们可以将这个定义推广到具有多通道的图信号。例如，在<code class="language-plaintext highlighter-rouge">recent</code>分量中，输入是 \(\mathbf{X}_{h}^{(r-1)}=(\mathbf{X}_{1},\mathbf{X}_{2},...,\mathbf{X}_{T_{r-1}}) \in \mathbb{R}^{N \times C_{r-1} \times T_{r-1}}\) ，其中每个节点的特征有 \(C_{r-1}\) 个通道。对于每个时间片 \(t\)，在图 \(\hat{\mathbf{X}}_{t}\) 上执行 \(C_{r}\) 滤波器，我们得到 \(g_{\theta} \ast_{G} \hat{\mathbf{X}}_{t}\)，其中 \(\theta=(\theta_{1},\theta_{1},...,\theta_{C_{r}}) \in \mathbb{R}^{K \times C_{r-1} \times C_{r}}\) 是卷积核参数。因此，每个节点都根据自己 \(0 \sim(K-1)\) 阶邻域的信息进行更新。</p><h3 id="时间维度的卷积">时间维度的卷积</h3><p>在图卷积操作已经在空间维度上捕捉到图上每个节点的邻域信息后，进一步堆叠时间维度上的标准卷积层，以通过在相邻时间切片处合并信息来更新节点的信号，如图5中的右侧部分所示。还以<code class="language-plaintext highlighter-rouge">recent</code>分量中的第 $r$ 层上的操作为例：</p>\[\pmb{X}_{h}^{(r)}=ReLU(\Phi \ast (ReLU(g_{\theta} \ast_{G} \pmb{\hat{\pmb{X}}}_{h}^{(r-1)}))) \in \mathbb{R}^{C_{r} \times N \times T_{r}}\]<p>其中，$\ast$ 表示标准卷积运算，$\Phi$ 是时间维度卷积核的参数，激活函数为<code class="language-plaintext highlighter-rouge">ReLU</code>。</p><p>总之，时空卷积模块能够很好地捕捉交通数据的时间和空间特征。时空注意模块和时空卷积模块形成时空块。堆叠多个时空块以进一步提取更大范围的动态时空相关性。最后，添加一个全连接层，以确保每个组件的输出具有与预测目标相同的尺寸和形状。最后一个全连接层使用<code class="language-plaintext highlighter-rouge">ReLU</code>作为激活函数。</p><h2 id="多组件融合">多组件融合</h2><p>在本节中，我们将讨论如何整合这三个组件的输出。以预测周五上午<code class="language-plaintext highlighter-rouge">8:00</code>整个交通网络的交通流量为例。可以观察到，一些地区的交通流在上午有明显的高峰期，因此日周期和周周期分量的输出更为关键。然而，在其他一些地方没有明显的交通周期模式，因此日周期和周周期成分可能没有什么用。因此，当融合不同组件的输出时，对于每个节点，三个组件的影响权重不同，应该从历史数据中学习。因此，融合后的最终预测结果为：</p>\[\mathbf{\hat{Y}}=\mathbf{W_{h}} \ \odot \mathbf{\hat{Y}}_{h} + \mathbf{W_{d}} \ \odot \mathbf{\hat{Y}}_{d} + \mathbf{W_{w}} \ \odot \mathbf{\hat{Y}}_{w}\]<p>其中，\(\odot\) 是<code class="language-plaintext highlighter-rouge">Hadamard</code>乘积。\(\mathbf{W}_{h}\)、\(\mathbf{W}_{d}\) 和 \(\mathbf{W}_{w}\) 是学习参数，反映了三个时空组件对预测目标的影响程度。</p><h1 id="实验">实验</h1><p>为了评估模型的效果，我们在两个真实的公路交通数据集上进行了对比实验。</p><h2 id="数据集">数据集</h2><p>我们在加利福尼亚州的两个公路交通数据集<code class="language-plaintext highlighter-rouge">PeMSD4</code>和<code class="language-plaintext highlighter-rouge">PeMSD8</code>上验证我们的模型。数据集由<code class="language-plaintext highlighter-rouge">Caltrans</code>性能测量系统<code class="language-plaintext highlighter-rouge">PeMS</code>每<code class="language-plaintext highlighter-rouge">30</code>秒实时收集一次。流量数据从原始数据聚合为每5分钟一次。该系统在加利福尼亚州主要大都市地区的高速公路上部署了39000多个探测器。数据集中记录了有关传感器站的地理信息。我们的实验中考虑了三种交通测量，包括总流量、平均速度和平均占用率。</p><h3 id="pemsd4">PeMSD4</h3><p>它是指旧金山湾区的交通数据，包含29条道路上的3848个探测器。该数据集的时间跨度为2018年1月至2月。我们选择前50天的数据作为训练集，剩余数据作为测试集。</p><h3 id="pemsd8">PeMSD8</h3><p>它是2016年7月至8月圣贝纳迪诺的交通数据，包含8条道路上的1979个探测器。前50天的数据用作训练集，最后12天的数据为测试集。</p><h2 id="预处理">预处理</h2><p>我们移除了一些冗余探测器，以确保任何相邻探测器之间的距离超过3.5英里。最后，<code class="language-plaintext highlighter-rouge">PeMSD4</code>中有307个检测器，<code class="language-plaintext highlighter-rouge">PEMSV8</code>中有170个检测器。交通数据每5分钟聚合一次，因此每个检测器每天包含288个数据点。缺失值由线性插值填充。此外，数据通过零均值归一化 \(x^{'}=x-mean(x)\) 使平均值为<code class="language-plaintext highlighter-rouge">0</code>。</p><h2 id="设置">设置</h2><p>我们基于<code class="language-plaintext highlighter-rouge">MXNet1</code>框架实现了<code class="language-plaintext highlighter-rouge">ASTGCN</code>模型。根据<code class="language-plaintext highlighter-rouge">Kipf</code>和<code class="language-plaintext highlighter-rouge">Welling</code>，我们测试了切比雪夫多项式项数的不同取值 $K \in \lbrace 1, 2, 3 \rbrace$. 随着 $K$ 变大，预测效果略有提高。时间维度上的卷积核大小也是如此。</p><p>考虑到计算效率和预测效果的权衡，我们设置 $K=3$，并将沿时间维度的卷积核大小设置为<code class="language-plaintext highlighter-rouge">3</code>。在我们的模型中，所有图卷积层使用<code class="language-plaintext highlighter-rouge">64</code>个卷积核。所有时间卷积层使用<code class="language-plaintext highlighter-rouge">64</code>个卷积核，通过控制时间卷积的步长来调整数据的时间跨度。对于三个路段的长度，我们将其设置为：$T_{h}=24$，$T_{d}=12$，$T_{w}=24$。预测窗口的大小 $T_{p}=12$，也就是说，我们旨在预测未来一小时内的交通流量。</p><p>本文将计算值和真实值之间的均方误差<code class="language-plaintext highlighter-rouge">MSE</code>用作损失函数，并通过反向传播最小化。在训练阶段，批量大小为<code class="language-plaintext highlighter-rouge">64</code>，学习率为<code class="language-plaintext highlighter-rouge">0.0001</code>。此外，为了验证本文提出的时空注意机制的影响，我们还设计了一个降级版本的<code class="language-plaintext highlighter-rouge">ASTGCN</code>，即多分量时空图卷积网络<code class="language-plaintext highlighter-rouge">MSTGCN</code>，该网络取消了时空注意力。<code class="language-plaintext highlighter-rouge">MSTGCN</code>的设置与<code class="language-plaintext highlighter-rouge">ASTGCN</code>相同，只是没有时空注意力。</p><h2 id="基准">基准</h2><p>我们将本文的模型与下面的八个基准进行对比：</p><ul><li><code class="language-plaintext highlighter-rouge">HA</code>: <code class="language-plaintext highlighter-rouge">Historical Average method</code>. 我们使用最后<code class="language-plaintext highlighter-rouge">12</code>个时间切片的平均值来预测下一个值。<li><code class="language-plaintext highlighter-rouge">ARIMA</code>: <code class="language-plaintext highlighter-rouge">Auto-Regressive Integrated Moving Average</code>. 自回归综合移动平均值是一种用于预测未来值的时间序列分析方法。<li><code class="language-plaintext highlighter-rouge">VAR</code>: <code class="language-plaintext highlighter-rouge">Vector Auto-Regressive</code>. 向量自回归是一种更先进的时间序列模型，可以捕捉所有交通流序列之间的成对关系。<li><code class="language-plaintext highlighter-rouge">LSTM</code>: <code class="language-plaintext highlighter-rouge">Long Short-Term Memory</code> 长-短期记忆网络，一种特殊的<code class="language-plaintext highlighter-rouge">RNN</code>模型。<li><code class="language-plaintext highlighter-rouge">GRU</code>: <code class="language-plaintext highlighter-rouge">Gated Recurrent Unit</code> 选通递归单元网络，一种特殊的<code class="language-plaintext highlighter-rouge">RNN</code>模型。<li><code class="language-plaintext highlighter-rouge">STGCN</code>: 基于空间方法的时空图卷积模型。<li><code class="language-plaintext highlighter-rouge">GLU-STGCN</code>: 一种带有选通机制的图卷积网络，专门用于流量预测。<li><code class="language-plaintext highlighter-rouge">GeoMAN</code>: 一种基于多级注意力的递归神经网络模型，用于地感时间序列预测问题。</ul><p>均方根误差<code class="language-plaintext highlighter-rouge">RMSE</code>和平均绝对误差<code class="language-plaintext highlighter-rouge">MAE</code>被用作评估指标。</p><h2 id="对比和结果分析">对比和结果分析</h2><p>我们将本文的模型与八种基线方法在<code class="language-plaintext highlighter-rouge">PeMSD4</code>和<code class="language-plaintext highlighter-rouge">PeMSD8</code>数据集上进行了比较。表1显示了未来一小时交通流预测效果的平均结果。</p><p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 1086 542'%3E%3C/svg%3E" data-proofer-ignore data-src="../../../../img/gnn/astgcn_paper/perf_comp.png" alt="image-20220801150230828" width="1086" height="542" /></p><p>从表1可以看出，我们的<code class="language-plaintext highlighter-rouge">ASTGCN</code>在两个数据集上的所有评估指标都达到了最佳效果。</p><p>可以观察到，传统时间序列分析方法的预测结果通常并不理想，这表明这些方法对非线性和复杂交通数据建模的能力有限。</p><p>相比之下，基于深度学习的方法通常比传统的时间序列分析方法获得更好的预测结果。其中，同时考虑时间和空间相关性的模型，包括<code class="language-plaintext highlighter-rouge">STGCN</code>、<code class="language-plaintext highlighter-rouge">GLU-STGCN</code>和<code class="language-plaintext highlighter-rouge">GeoMAN</code>以及我们模型的两个版本，优于传统的深度学习模型，如<code class="language-plaintext highlighter-rouge">LSTM</code>和<code class="language-plaintext highlighter-rouge">GRU</code>。</p><p>此外，<code class="language-plaintext highlighter-rouge">GeoMAN</code>的效果优于<code class="language-plaintext highlighter-rouge">STGCN</code>和<code class="language-plaintext highlighter-rouge">GLU-STGCN</code>，表明<code class="language-plaintext highlighter-rouge">GeoMAN</code>中应用的多级注意机制在捕获交通数据的动态变化方面是有效的。</p><p>我们的<code class="language-plaintext highlighter-rouge">MSTGCN</code>在没有任何注意力机制的情况下，取得了比以前的最优模型更好的结果，证明了我们的模型在描述公路交通数据的时空特征方面的优势。然后结合时空注意机制，我们的<code class="language-plaintext highlighter-rouge">ASTGCN</code>进一步减少了预测误差。</p><p>图6显示了各种方法的预测效果随着预测间隔增加的变化情况。总的来说，随着预测间隔变长，相应的预测难度越来越大，因此预测误差也会增加。</p><p>从图中可以看出，仅考虑时间相关性的方法可以在短期预测中取得良好的结果，例如<code class="language-plaintext highlighter-rouge">HA</code>、<code class="language-plaintext highlighter-rouge">ARIMA</code>、<code class="language-plaintext highlighter-rouge">LSTM</code>和<code class="language-plaintext highlighter-rouge">GRU</code>。然而，随着预测间隔的增加，其预测精度急剧下降。</p><p>相比之下，<code class="language-plaintext highlighter-rouge">VAR</code>的性能下降比这些方法慢。这主要是因为<code class="language-plaintext highlighter-rouge">VAR</code>可以同时考虑在长期预测中更重要的时空相关性。然而，当交通网络的规模变得更大，即模型中考虑的时间序列更多时，<code class="language-plaintext highlighter-rouge">VAR</code>的预测误差增加，如图6所示，其在<code class="language-plaintext highlighter-rouge">PeMSD4</code>上的效果不如<code class="language-plaintext highlighter-rouge">PeMSD8</code>。</p><p>深度学习方法的误差随着预测间隔的增加而缓慢增加，其整体性能良好。</p><p>我们的<code class="language-plaintext highlighter-rouge">ASTGCN</code>模型几乎始终具有最佳的预测效果。特别是在长期预测中，<code class="language-plaintext highlighter-rouge">ASTGCN</code>与其他基线之间的差异更为显著，表明将注意力机制与图卷积相结合的策略可以更好地挖掘交通数据的动态时空模式。</p><p>为了直观地研究注意力机制在我们的模型中的作用，我们进行了一个案例研究：从<code class="language-plaintext highlighter-rouge">PeMSD8</code>中选取一个子图，其中包含10个检测器，并显示训练集中检测器之间的平均空间注意力矩阵。如图7右侧所示，在空间注意力矩阵中，第 $i$ 行表示每个检测器和第 $i$ 检测器之间的相关强度。例如，看最后一行，我们可以知道第9个检测器上的交通流与第3个和第8个检测器的交通流密切相关。这是合理的，因为这三个检测器在真实交通网络上的空间很近，如图7左侧所示。因此，我们的模型不仅实现了最佳预测性能，而且显示了可解释性优势。</p><h1 id="结论">结论</h1><p>本文提出了一种新的基于注意力机制的时空图卷积模型<code class="language-plaintext highlighter-rouge">ASTGCN</code>，并成功地应用于交通流预测。该模型将<strong>时空注意力机制</strong>和<strong>时空卷积</strong>相结合，包括空间维度的<strong>图卷积</strong>和时间维度的<strong>标准卷积</strong>，以同时捕获交通数据的<strong>动态时空特征</strong>。</p><p>在两个真实数据集上的实验表明，该模型的预测精度优于现有模型。代码发布于<a href="https://github.com/wanhuaiyu/ASTGCN">https://github.com/wanhuaiyu/ASTGCN</a>.</p><p>实际上，公路交通流受到许多外部因素的影响，如天气和社会事件。未来，我们将考虑一些外部影响因素，以进一步提高预测精度。因为<code class="language-plaintext highlighter-rouge">ASTGCN</code>是一个对于图结构数据的通用时空预测框架，我们还可以将其应用于其他实际应用，例如估计到达时间。</p><h1 id="问题-1">问题</h1><ol><li><p>实现中的final_conv作用是什么？</p><p>卷积的通用作用是为了进行<strong>特征提取</strong>，进行<a href="https://so.csdn.net/so/search?q=特征提取&amp;spm=1001.2101.3001.7020">特征提取</a>后，需要处理的信息就急剧减少，可以极大的加快运行速度，当然这只是我认为其中比较重要的一个原因，使用卷积+池化还有其他的作用，需要详细研究的可以看这篇文章，写的非常详细： <a href="https://easyaitech.medium.com/一文看懂卷积神经网络-cnn-基本原理-独特价值-实际应用-6047fb2add35">一文看懂卷积神经网络-CNN</a></p><li></ol></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/gnn/'>GNN</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/astgcn/" class="post-tag no-text-decoration" >ASTGCN</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting - zuo&url=https://dazuozcy.github.io/posts/ASTGCN/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting - zuo&u=https://dazuozcy.github.io/posts/ASTGCN/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=ASTGCN-Attention Based Spatial-Temporal Graph Convolutional Networks for Traffic Flow Forecasting - zuo&url=https://dazuozcy.github.io/posts/ASTGCN/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/simd/">SIMD</a><li><a href="/posts/new-from-cpp11/">C++11开始的新特性</a><li><a href="/posts/keywords/">关键字</a><li><a href="/posts/empty-class/">class的内存模型</a><li><a href="/posts/diff-between-c-cpp/">C++ vs C</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/gpu/">GPU</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/openmp/">openMP</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/parallel-computing/">Parallel Computing</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/forecasting-at-scale/">Forecasting at Scale</a> <a class="post-tag" href="/tags/onednn/">oneDNN</a> <a class="post-tag" href="/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/">智能指针</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/GAT/"><div class="card-body"> <span class="timeago small" > Jul 2, 2020 <i class="unloaded">2020-07-02T20:19:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>GAT</h3><div class="text-muted small"><p> GCN缺点： 模型对于同阶邻域上分配给不同邻居的权重是完全相同的（也就是GAT论文里说的：无法允许为邻居中的不同节点指定不同的权重）。这一点限制了模型对于空间信息的相关性的捕捉能力，这也是在很多任务上不如GAT的根本原因。 GCN结合临近节点特征的方式和图的结构依依相关，这局限了训练所得模型在其他图结构上的泛化能力。 GAT提出了用注意力机制对邻近节点特征加权求和。邻近节点特...</p></div></div></a></div><div class="card"> <a href="/posts/GCN/"><div class="card-body"> <span class="timeago small" > Jul 2, 2020 <i class="unloaded">2020-07-02T20:19:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>GCN</h3><div class="text-muted small"><p> Graph Convolutional Networks(GCN): 图卷积神经网络，实际上跟CNN的作用类似，就是一个特征提取器，只不过它的对象是图数据。GCN精妙地设计了一种从图数据中提取特征的方法，从而让我们可以使用这些特征去对图数据进行：节点分类 、图分类、边预测，还可顺便得到图的嵌入表示。 【图结构】之图神经网络GCN详解 图卷积网络(Graph Convolutional N...</p></div></div></a></div><div class="card"> <a href="/posts/GNN/"><div class="card-body"> <span class="timeago small" > Jul 2, 2020 <i class="unloaded">2020-07-02T20:19:00+08:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>GNN</h3><div class="text-muted small"><p> CNN系列： 做图像识别时，对象是图片，是一个二维的结构，于是人们发明了CNN这种神奇的模型来提取图片的特征。CNN的核心在于它的kernel，kernel是一个个小窗口，在图片上平移，通过卷积的方式来提取特征。这里的关键在于图片结构上的平移不变性： 一个小窗口无论移动到图片的哪一个位置，其内部的结构都是一模一样的，因此是CNN可以实现所在。 RNN系列:...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/chebnet/" class="btn btn-outline-primary" prompt="Older"><p>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</p></a> <a href="/posts/EGConv/" class="btn btn-outline-primary" prompt="Newer"><p>EGConv-DO WE NEED ANISOTROPIC GRAPH NEURAL NETWORKS</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://github.com/dazuozcy">zuo</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/gpu/">GPU</a> <a class="post-tag" href="/tags/cuda/">CUDA</a> <a class="post-tag" href="/tags/openmp/">openMP</a> <a class="post-tag" href="/tags/c/">C++</a> <a class="post-tag" href="/tags/parallel-computing/">Parallel Computing</a> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/forecasting-at-scale/">Forecasting at Scale</a> <a class="post-tag" href="/tags/onednn/">oneDNN</a> <a class="post-tag" href="/tags/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/">智能指针</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><script src="https://cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js"></script> <script> $(function() { let initTheme = "default"; if ($("html[mode=dark]").length > 0 || ($("html[mode]").length == 0 && window.matchMedia("(prefers-color-scheme: dark)").matches ) ) { initTheme = "dark"; } let mermaidConf = { theme: initTheme /* <default|dark|forest|neutral> */ }; /* Markdown converts to HTML */ $("pre").has("code.language-mermaid").each(function() { let svgCode = $(this).children().html(); $(this).addClass("unloaded"); $(this).after(`<div class=\"mermaid\">${svgCode}</div>`); }); mermaid.initialize(mermaidConf); }); </script><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://dazuozcy.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script> <script async src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id="></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', ''); }); </script> <script src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script>
